{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to MkDocs For full documentation visit mkdocs.org . Commands mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit. Project layout mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Home"},{"location":"#welcome-to-mkdocs","text":"For full documentation visit mkdocs.org .","title":"Welcome to MkDocs"},{"location":"#commands","text":"mkdocs new [dir-name] - Create a new project. mkdocs serve - Start the live-reloading docs server. mkdocs build - Build the documentation site. mkdocs -h - Print help message and exit.","title":"Commands"},{"location":"#project-layout","text":"mkdocs.yml # The configuration file. docs/ index.md # The documentation homepage. ... # Other markdown pages, images and other files.","title":"Project layout"},{"location":"dataAnalysis/dataAnalysis01/","text":"python\u6570\u636e\u5206\u6790 01 python packages scientific computing \u79d1\u5b66\u8ba1\u7b97 pandas - \u6570\u636e\u6784\u5efa\u548c\u5de5\u5177\uff0c\u6838\u5fc3\u662fdataframe numpy - \u4e3b\u8981\u662f\u6570\u5217\u548c\u77e9\u9635 scipy - \u6570\u5b66\u516c\u5f0f\u548c\u4f18\u5316 visualization \u53ef\u89c6\u5316\u5448\u73b0 matplotlib - \u56fe\u8868\u7ed8\u5236\uff0c\u662f\u6700\u53d7\u6b22\u8fce\u7684\u5e93\u4e4b\u4e00 seaborn - \u70ed\u529b\u56fe\u3001\u65f6\u95f4\u7ebf\u56fe\u3001\u5c0f\u63d0\u7434\u56fe algorithmic \u7b97\u6cd5 scikit-learn - \u673a\u5668\u5b66\u4e60\u3001\u9012\u5f52\u3001\u805a\u7c7b statsmodels - \u7edf\u8ba1\u6a21\u578b\u3001\u7edf\u8ba1\u6d4b\u8bd5 Import and Exporting Data in python Import file importing \u6709\u4e24\u4e2a\u5173\u952e\u7684\u5c5e\u6027\u9700\u8981\u8003\u8651 * format \u6587\u4ef6\u683c\u5f0f: csv, json, xlsx, hdf * file path \u6587\u4ef6\u8def\u5f84 * \u672c\u5730\u6587\u4ef6 /desktop/mydata.csv * \u7f51\u7edc\u8bfb\u53d6 https://archive.edu/autos/imports-85.data Importing a csv into python import pandas as pd url = \"<url>\" # \u6807\u660e\u6587\u4ef6\u662f\u5426\u5177\u6709 header df = pd . read_csv ( url , header = None ) \u5e38\u7528python\u65b9\u6cd5 * df \u8fd4\u56de\u6574\u5f20\u6570\u636e\u8868\u5355 * df.head(n) \u8fd4\u56de\u524dn\u884c\u7684\u6570\u636e * df.tail(n) \u8fd4\u56de\u540en\u884c\u7684\u6570\u636e * df.columns = <headers> \u8bbe\u5b9a\u5217\u540d\uff0c\u5176\u4e2d \u7684\u5f62\u5f0f\u662f\u5217\u8868 pandas\u652f\u6301\u8bfb\u53d6\u7684\u6570\u636e\u683c\u5f0f Data Format Read Save csv pd.read_csv() df.to_csv() json pd.read_json() df.to_json() excel pd.read_excel() df.to_excel() sql pd.read_sql() df.to_sql() export file path = \"desktop/completed.csv\" # index \u662f\u8868\u5355\u4e2d\u7684 primary key, \u5728\u5bfc\u51fa\u65f6\u53ef\u4ee5\u4e0d\u5305\u62ecindex df . to_csv ( path , index = False ) Access Data using python Python \u4f7f\u7528 API \u6765\u8fde\u63a5\u5230\u6570\u636e\u5e93\u3002 \u4ee5\u4e0a\u662f\u4f7f\u7528 SQL API \u7684\u4e00\u5f20\u793a\u4f8b\u56fe\u3002 DB API \u662fpython\u4e2d\u7684\u6807\u51c6\u5e93\uff0c\u7528\u6765\u8fde\u63a5\u6570\u636e\u5e93\u3002\u4e14DB API\u5177\u6709\u53ef\u4ee5\u8fde\u63a5\u591a\u4e2a\u6570\u636e\u5e93\u7684\u4f18\u52bf\u3002 * connection objects * database connections * manage transactions * cursor objects * database queries * connection methods * cursor() \u8fd4\u56de\u4e00\u4e2a\u65b0\u7684 cursor object * commit() \u786e\u8ba4\u6267\u884c\u7f13\u5b58\u4e2d\u7684\u64cd\u4f5c * rollback() \u64a4\u9500\u5728\u7f13\u5b58\u4e2d\u7684\u64cd\u4f5c * close() \u5173\u95ed connection from dbmodule import connect # \u521b\u5efa connection \u5bf9\u8c61 conn = connect ( 'databasename' , 'username' , 'pwd' ) # \u521b\u5efa cursor \u5bf9\u8c61 cursor = conn . cursor () # \u6267\u884c\u67e5\u8be2\u8bed\u53e5 cursor . execute ( \"select * from mytable\" ) result = cursor . fetchall () # \u7ed3\u675f\u8fde\u63a5 cursor . close () conn . close () Analyze Data in python \u4e3a\u4ec0\u4e48\u6211\u4eec\u9700\u8981\u5728\u5bfc\u5165\u6570\u636e\u540e\u786e\u5b9a\u6570\u636e\u7684\u7c7b\u578b\u5462\uff1f 1. \u907f\u514d\u53ef\u80fd\u51fa\u73b0\u7684 typo \u548c\u4fe1\u606f\u9519\u8bef 2. \u786e\u4fdd\u548cpython\u65b9\u6cd5\u7684\u9002\u914d\u6027 \u68c0\u9a8c\u6570\u636e\u683c\u5f0f\u4f7f\u7528 df.dtypes \u3002pandas\u4e2d\u7684\u6570\u636e\u683c\u5f0f\u6709 object, int64, float64\u548cdatetime64, timedelta[ns]\u3002 \u4f7f\u7528 df.describe() \u65b9\u6cd5\u53ef\u4ee5\u8fd4\u56de\u7edf\u8ba1\u5173\u952e\u6570\u636e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5982\u679c\u662f\u9488\u5bf9\u67d0\u4e00\u884c\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528 df[[<col1>,<col2>]].describe() \u3002 Pic 0330-1 \u4f7f\u7528 df.descirbe(include=\"all\") \u4f1a\u8fd4\u56de\u4e00\u5f20\u66f4\u5b8c\u6574\u7684\u3001\u5305\u62ec\u6240\u6709\u5217\u7684\u7edf\u8ba1\u5173\u952e\u6570\u636e\uff0c\u5305\u542b unique, top, freq\u7b49\u3002 * unique: \u51fa\u73b0\u4e86\u591a\u5c11\u4e2a\u4e0d\u540c\u7684\u503c * top: \u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u503c\uff0c\u5373 mode * freq: top\u503c\u51fa\u73b0\u7684\u6b21\u6570 \u4f7f\u7528 df.info() \u4f1a\u8fd4\u56de\u5217\u7684\u6570\u636e\u7c7b\u578b\uff0c\u4e0d\u662f\u7a7a\u767d\u6570\u503c\u7684\u8ba1\u503c\uff0cdtypes\u7684freq\u7edf\u8ba1\uff0c\u5185\u5b58\u4f7f\u7528\u3002 \u4f7f\u7528 df.replace(<value1>, <value2>) \u53ef\u4ee5\u4f7f\u7528value2\u6765\u66ff\u6362\u6389value1\u3002\u5982 df.replace('?',np.NaN) \u5219\u662f\u4f7f\u7528numpy\u4e2d\u7684NaN\u6765\u66ff\u6362\u6389?\u3002 \u4f7f\u7528 df.dropna() \u53ef\u4ee5\u6ee4\u9664\u7f3a\u5931\u6570\u636e\u3002 axis=0 \u5bf9\u884c\u8fdb\u884c\u64cd\u4f5c\uff0c axis=1 \u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 * df.dropna(how=\"all\") \u53ea\u4e22\u5f03\u5168\u4e3a\u7f3a\u5931\u503c\u7684\u884c * df.dropna(axis=1) \u4e22\u5f03\u6709\u7f3a\u5931\u503c\u7684\u5217\uff0c\u901a\u5e38\u4e0d\u4f1a\u64cd\u4f5c\uff0c\u56e0\u4e3a\u4f1a\u7f3a\u5931\u4e00\u4e2a\u7279\u5f81 * df.dropna(axis=1, how=\"all\") \u53ea\u4e22\u5f03\u5168\u4e3a\u7f3a\u5931\u503c\u7684\u5217 * df.dropna(axis=0, subset=[\"age\",\"sex\"] \u4e22\u5f03age, sex\u4e24\u5217\u4e2d\u6709\u7f3a\u5931\u503c\u7684\u884c * df.dropna(thresh=2) \u4fdd\u7559\u81f3\u5c11\u67092\u4e2a\u975e\u7a7a\u767d\u503c\u7684\u884c","title":"\u6570\u636e\u5e93\u8fde\u63a5\u548c pandas \u65b9\u6cd5"},{"location":"dataAnalysis/dataAnalysis01/#python-01","text":"","title":"python\u6570\u636e\u5206\u6790 01"},{"location":"dataAnalysis/dataAnalysis01/#python-packages","text":"scientific computing \u79d1\u5b66\u8ba1\u7b97 pandas - \u6570\u636e\u6784\u5efa\u548c\u5de5\u5177\uff0c\u6838\u5fc3\u662fdataframe numpy - \u4e3b\u8981\u662f\u6570\u5217\u548c\u77e9\u9635 scipy - \u6570\u5b66\u516c\u5f0f\u548c\u4f18\u5316 visualization \u53ef\u89c6\u5316\u5448\u73b0 matplotlib - \u56fe\u8868\u7ed8\u5236\uff0c\u662f\u6700\u53d7\u6b22\u8fce\u7684\u5e93\u4e4b\u4e00 seaborn - \u70ed\u529b\u56fe\u3001\u65f6\u95f4\u7ebf\u56fe\u3001\u5c0f\u63d0\u7434\u56fe algorithmic \u7b97\u6cd5 scikit-learn - \u673a\u5668\u5b66\u4e60\u3001\u9012\u5f52\u3001\u805a\u7c7b statsmodels - \u7edf\u8ba1\u6a21\u578b\u3001\u7edf\u8ba1\u6d4b\u8bd5","title":"python packages"},{"location":"dataAnalysis/dataAnalysis01/#import-and-exporting-data-in-python","text":"","title":"Import and Exporting Data in python"},{"location":"dataAnalysis/dataAnalysis01/#import-file","text":"importing \u6709\u4e24\u4e2a\u5173\u952e\u7684\u5c5e\u6027\u9700\u8981\u8003\u8651 * format \u6587\u4ef6\u683c\u5f0f: csv, json, xlsx, hdf * file path \u6587\u4ef6\u8def\u5f84 * \u672c\u5730\u6587\u4ef6 /desktop/mydata.csv * \u7f51\u7edc\u8bfb\u53d6 https://archive.edu/autos/imports-85.data Importing a csv into python import pandas as pd url = \"<url>\" # \u6807\u660e\u6587\u4ef6\u662f\u5426\u5177\u6709 header df = pd . read_csv ( url , header = None ) \u5e38\u7528python\u65b9\u6cd5 * df \u8fd4\u56de\u6574\u5f20\u6570\u636e\u8868\u5355 * df.head(n) \u8fd4\u56de\u524dn\u884c\u7684\u6570\u636e * df.tail(n) \u8fd4\u56de\u540en\u884c\u7684\u6570\u636e * df.columns = <headers> \u8bbe\u5b9a\u5217\u540d\uff0c\u5176\u4e2d \u7684\u5f62\u5f0f\u662f\u5217\u8868 pandas\u652f\u6301\u8bfb\u53d6\u7684\u6570\u636e\u683c\u5f0f Data Format Read Save csv pd.read_csv() df.to_csv() json pd.read_json() df.to_json() excel pd.read_excel() df.to_excel() sql pd.read_sql() df.to_sql()","title":"Import file"},{"location":"dataAnalysis/dataAnalysis01/#export-file","text":"path = \"desktop/completed.csv\" # index \u662f\u8868\u5355\u4e2d\u7684 primary key, \u5728\u5bfc\u51fa\u65f6\u53ef\u4ee5\u4e0d\u5305\u62ecindex df . to_csv ( path , index = False )","title":"export file"},{"location":"dataAnalysis/dataAnalysis01/#access-data-using-python","text":"Python \u4f7f\u7528 API \u6765\u8fde\u63a5\u5230\u6570\u636e\u5e93\u3002 \u4ee5\u4e0a\u662f\u4f7f\u7528 SQL API \u7684\u4e00\u5f20\u793a\u4f8b\u56fe\u3002 DB API \u662fpython\u4e2d\u7684\u6807\u51c6\u5e93\uff0c\u7528\u6765\u8fde\u63a5\u6570\u636e\u5e93\u3002\u4e14DB API\u5177\u6709\u53ef\u4ee5\u8fde\u63a5\u591a\u4e2a\u6570\u636e\u5e93\u7684\u4f18\u52bf\u3002 * connection objects * database connections * manage transactions * cursor objects * database queries * connection methods * cursor() \u8fd4\u56de\u4e00\u4e2a\u65b0\u7684 cursor object * commit() \u786e\u8ba4\u6267\u884c\u7f13\u5b58\u4e2d\u7684\u64cd\u4f5c * rollback() \u64a4\u9500\u5728\u7f13\u5b58\u4e2d\u7684\u64cd\u4f5c * close() \u5173\u95ed connection from dbmodule import connect # \u521b\u5efa connection \u5bf9\u8c61 conn = connect ( 'databasename' , 'username' , 'pwd' ) # \u521b\u5efa cursor \u5bf9\u8c61 cursor = conn . cursor () # \u6267\u884c\u67e5\u8be2\u8bed\u53e5 cursor . execute ( \"select * from mytable\" ) result = cursor . fetchall () # \u7ed3\u675f\u8fde\u63a5 cursor . close () conn . close ()","title":"Access Data using python"},{"location":"dataAnalysis/dataAnalysis01/#analyze-data-in-python","text":"\u4e3a\u4ec0\u4e48\u6211\u4eec\u9700\u8981\u5728\u5bfc\u5165\u6570\u636e\u540e\u786e\u5b9a\u6570\u636e\u7684\u7c7b\u578b\u5462\uff1f 1. \u907f\u514d\u53ef\u80fd\u51fa\u73b0\u7684 typo \u548c\u4fe1\u606f\u9519\u8bef 2. \u786e\u4fdd\u548cpython\u65b9\u6cd5\u7684\u9002\u914d\u6027 \u68c0\u9a8c\u6570\u636e\u683c\u5f0f\u4f7f\u7528 df.dtypes \u3002pandas\u4e2d\u7684\u6570\u636e\u683c\u5f0f\u6709 object, int64, float64\u548cdatetime64, timedelta[ns]\u3002 \u4f7f\u7528 df.describe() \u65b9\u6cd5\u53ef\u4ee5\u8fd4\u56de\u7edf\u8ba1\u5173\u952e\u6570\u636e\uff0c\u5982\u4e0b\u56fe\u6240\u793a\u3002\u5982\u679c\u662f\u9488\u5bf9\u67d0\u4e00\u884c\u7684\uff0c\u53ef\u4ee5\u4f7f\u7528 df[[<col1>,<col2>]].describe() \u3002 Pic 0330-1 \u4f7f\u7528 df.descirbe(include=\"all\") \u4f1a\u8fd4\u56de\u4e00\u5f20\u66f4\u5b8c\u6574\u7684\u3001\u5305\u62ec\u6240\u6709\u5217\u7684\u7edf\u8ba1\u5173\u952e\u6570\u636e\uff0c\u5305\u542b unique, top, freq\u7b49\u3002 * unique: \u51fa\u73b0\u4e86\u591a\u5c11\u4e2a\u4e0d\u540c\u7684\u503c * top: \u51fa\u73b0\u9891\u7387\u6700\u9ad8\u7684\u503c\uff0c\u5373 mode * freq: top\u503c\u51fa\u73b0\u7684\u6b21\u6570 \u4f7f\u7528 df.info() \u4f1a\u8fd4\u56de\u5217\u7684\u6570\u636e\u7c7b\u578b\uff0c\u4e0d\u662f\u7a7a\u767d\u6570\u503c\u7684\u8ba1\u503c\uff0cdtypes\u7684freq\u7edf\u8ba1\uff0c\u5185\u5b58\u4f7f\u7528\u3002 \u4f7f\u7528 df.replace(<value1>, <value2>) \u53ef\u4ee5\u4f7f\u7528value2\u6765\u66ff\u6362\u6389value1\u3002\u5982 df.replace('?',np.NaN) \u5219\u662f\u4f7f\u7528numpy\u4e2d\u7684NaN\u6765\u66ff\u6362\u6389?\u3002 \u4f7f\u7528 df.dropna() \u53ef\u4ee5\u6ee4\u9664\u7f3a\u5931\u6570\u636e\u3002 axis=0 \u5bf9\u884c\u8fdb\u884c\u64cd\u4f5c\uff0c axis=1 \u5bf9\u5217\u8fdb\u884c\u64cd\u4f5c\u3002 * df.dropna(how=\"all\") \u53ea\u4e22\u5f03\u5168\u4e3a\u7f3a\u5931\u503c\u7684\u884c * df.dropna(axis=1) \u4e22\u5f03\u6709\u7f3a\u5931\u503c\u7684\u5217\uff0c\u901a\u5e38\u4e0d\u4f1a\u64cd\u4f5c\uff0c\u56e0\u4e3a\u4f1a\u7f3a\u5931\u4e00\u4e2a\u7279\u5f81 * df.dropna(axis=1, how=\"all\") \u53ea\u4e22\u5f03\u5168\u4e3a\u7f3a\u5931\u503c\u7684\u5217 * df.dropna(axis=0, subset=[\"age\",\"sex\"] \u4e22\u5f03age, sex\u4e24\u5217\u4e2d\u6709\u7f3a\u5931\u503c\u7684\u884c * df.dropna(thresh=2) \u4fdd\u7559\u81f3\u5c11\u67092\u4e2a\u975e\u7a7a\u767d\u503c\u7684\u884c","title":"Analyze Data in python"},{"location":"dataAnalysis/dataAnalysis02/","text":"Python\u6570\u636e\u5206\u679002 \u6570\u636e\u9884\u5148\u5904\u7406 \u5c06\u6570\u636e\u8fdb\u884c\u4ece\u539f\u59cb\u6570\u636e -> \u53ef\u7528\u6570\u636e\u7684\u8f6c\u6362\u3002data pre-processing \u6709\u65f6\u5019\u4e5f\u88ab\u79f0\u4e3a\u6570\u636e\u6e05\u6d17\uff08data cleaning\uff09\u6216data wrangling\u3002 handle missing value \u627e\u51fa\u5e76\u5904\u7406\u9057\u5931\u7684\u6570\u636e data formating \u7edf\u4e00\u6570\u636e\u683c\u5f0f data normalization \u6807\u51c6\u5316\u6570\u636e (centering / scaling) \u786e\u5b9a\u4f7f\u7528\u7684\u6570\u636e\u8303\u7574 data binning \u6570\u636e\u5206\u7ec4 \u5904\u7406\u9057\u5931\u7684\u6570\u636e \u901a\u5e38\u6765\u8bf4\u9057\u5931\u7684\u6570\u636e\u8868\u73b0\u5f62\u5f0f\u4e3a \u201c?\u201d \u201cN?A\u201d 0 \u6216\u8005\u7a7a\u767d\u3002\u6709\u4ee5\u4e0b\u51e0\u79cd\u5904\u7406\u65b9\u5f0f 1. \u67e5\u770b\u6570\u636e\u7684\u6570\u636e\u6e90\uff0c\u786e\u4fdd\u6e90\u5934\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u53ca\u65f6\u6027 2. \u79fb\u9664\u6570\u636e\uff08\u79fb\u9664\u5355\u4e2a\u6570\u636e \u6216 \u79fb\u9664\u6574\u4e2a\u53d8\u91cf\uff09 3. \uff08\u4f7f\u7528\u5e73\u5747\u503c/mode\u503c\uff09\u66ff\u6362\u9057\u5931\u7684\u6570\u636e\uff0c\u4f46\u8be5\u79cd\u505a\u6cd5\u4f1a\u964d\u4f4e\u6570\u636e\u7684\u51c6\u786e\u6027 \u5220\u9664\u9057\u5931\u503c \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 dataframes.dropna() \u65b9\u6cd5\u3002 * axis=0 \u5220\u9664\u51fa\u73b0\u7a7a\u767d\u503c\u7684\u6574\u884c * axis=1 \u5220\u9664\u51fa\u73b0\u7a7a\u767d\u503c\u7684\u6574\u5217\u3002 \u4e00\u4e2a\u793a\u4f8b\u4e3a df.dropna(subset=[\"price'], axis=0, inplace=True) \u3002 \u66ff\u6362\u9057\u5931\u503c \u53ef\u4ee5\u4f7f\u7528 df.replace(missing_value, new_value) \u3002\u73b0\u5728\u5047\u8bbe\u6211\u4eec\u60f3\u8981\u7528\u8be5\u5217\u7684\u5e73\u5747\u503c\u6765\u66ff\u6362\u6389\u51fa\u73b0\u7684\u9057\u5931\u503c\u3002 # \u8ba1\u7b97\u51fa\u8be5\u5217\u7684\u5e73\u5747\u503c mean = df [ \"normalized-losses\" ] . mean () # \u9650\u5b9a\u4f5c\u7528\u8303\u7574\u7684\u5217\uff0c\u518d\u4f7f\u7528 df.replace() \u65b9\u6cd5 df [ \"normalized-losses\" ] . replace ( np . nan , mean ) \u7edf\u4e00\u3001\u5408\u7406\u7684\u6570\u636e\u683c\u5f0f Data Standardization \u6570\u636e\u901a\u5e38\u7531\u591a\u4eba\u4ece\u4e0d\u540c\u6e20\u9053\u6536\u96c6\uff0c\u5e76\u4e14\u4ee5\u591a\u6837\u7684\u5f62\u5f0f\u4fdd\u5b58\u3002\u7edf\u4e00\u6570\u636e\u683c\u5f0f\u4f1a\u4e3a\u4e4b\u540e\u7684\u6570\u636e\u5206\u6790\u5e26\u6765\u5f88\u5927\u7684\u4fbf\u5229\u3002\u5728\u5f88\u591a\u91d1\u79d1\u4f01\u4e1a\u548c\u91d1\u63a7\u516c\u53f8\u4e2d\u4e5f\u5728\u4e0d\u65ad\u63d0\u5021\u7edf\u4e00\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u79f0\u4f5c \u6570\u636e\u6cbb\u7406 \u3002 \u4ee5\u4e0a\u7684\u793a\u4f8b\u5c55\u793a\u4e86\u6570\u636e-\u4eba\u5458\u7684\u57ce\u5e02\u53ef\u4ee5\u8868\u73b0\u4e3a \u201cNew York\u201d \u201cNY\u201d \u6216\u8005 \u201cN.Y\u201d\uff0c\u5728\u8fd9\u79cd\u573a\u666f\u4e0b\u9700\u8981\u7edf\u4e00\u5176\u6570\u636e\u683c\u5f0f\u3002 \u8fd8\u6709\u4e00\u79cd\u573a\u666f\u662f\u5c06\u6570\u636e\u8f6c\u6362\u4e3a\u6700\u6613\u8bfb\u3001\u6700\u5408\u7406\u3001\u6700\u7b26\u5408\u573a\u666f\u7684\u5355\u5143\u3002\u5982\u6444\u6c0f\u5ea6\u548c\u534e\u6c0f\u5ea6\uff0c\u516c\u91cc\u548c\u82f1\u91cc\u3002\u5728\u51b3\u5b9a\u4f7f\u7528\u4ec0\u4e48\u5355\u4f4d\u7684\u65f6\u5019\u53ef\u4ee5\u8003\u8651\u4f1a\u9605\u8bfb\u8fd9\u4efd\u62a5\u544a\u3001\u53c2\u4e0e\u6570\u636e\u5206\u6790\u4eba\u5458\u7684\u60ef\u4f8b\u548c\u62a5\u544a\u7528\u9014\u3002\u5047\u8bbe\u6211\u4eec\u73b0\u5728\u9700\u8981\u5c06\u6c7d\u8f66\u7684 mpg \u8f6c\u6362\u4e3a /100km\u3002\u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 # \u8c03\u6574\u6570\u636e\u683c\u5f0f df [ \"city-mpg\" ] = 235 / [ \"city-mpg\" ] # \u91cd\u547d\u540d\u5217\u540d\uff0c\u53ef\u4ee5\u770b\u5230 columns \u53d8\u91cf\u7684\u8d4b\u503c\u6709\u70b9\u7c7b\u4f3c\u4e8e\u8bcd\u5178 # rename \u4e00\u822c\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570 \u53c2\u65701\u4e3acolumns \u53c2\u65702\u4e3ainplace df . rename ( columns = { \"city_mpg\" : \"city-L/100kn\" }, inplace = True ) \u5728\u8fd9\u91cc\u9700\u8981\u5f15\u8fdb pandas \u4e2d\u7684\u6570\u636e\u7c7b\u578b\u3002\u6709 objects (\u201chello\u201d), int64 (1,3) \u548c Float64 (3.1415)\u3002\u6709\u65f6\u5019\u5f53\u6211\u4eec\u8c03\u6574\u6570\u636e\u7c7b\u578b\u65f6\u4f1a\u53d1\u751f\u6570\u636e\u7c7b\u578b\u548c\u8c03\u6574\u540e\u7684\u6570\u636e\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u3002 \u4f7f\u7528 df.dtypes() \u53ef\u4ee5\u67e5\u8be2\u6570\u636e\u7c7b\u578b \u4f7f\u7528 df.astype() \u53ef\u4ee5\u8f6c\u6362\u6570\u636e\u7c7b\u578b\uff0c\u5982 df[\"price\"] = df[\"price].astype(\"float\") \u6807\u51c6\u5316\u6570\u636e\u6bd4\u4f8b Data Normalization \u60f3\u8c61\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e00\u4e2a\u6d4b\u8bd5\u6536\u96c6\u4e86\u88ab\u8bd5\u8005\u7684\u5e74\u9f84\u548c\u6536\u5165\uff0c\u5e74\u9f84\u7684\u8303\u7574\u4f1a\u572810-100\u95f4\u6ce2\u52a8\uff0c\u4f46\u662f\u6536\u5165\u7684\u6ce2\u52a8\u8303\u7574\u4f1a\u8fdc\u8fdc\u5927\u4e8e\u5e74\u9f84\uff0c\u57282,000-200,000\u6ce2\u52a8\u3002\u8fd9\u6837\u6536\u5165\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u4f1a\u8fdc\u8fdc\u5927\u4e8e\u5e74\u9f84\u7684\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u5373\u7ed3\u679c\u4f1a\u6709\u504f\u5dee\u3002 \u6709\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f\u53ef\u4ee5\u89e3\u51b3\u6570\u636e\u6bd4\u4f8b\u7684\u95ee\u9898 1. Simple feature scaling: \u5373\u4f7f\u7528 \u4e2a\u4f53\u503c/\u6700\u5927\u503c 2. Min-Max: \u5373\u4f7f\u7528 (\u4e2a\u4f53\u503c-\u6700\u5c0f\u503c) / (\u6700\u5927\u503c-\u6700\u5c0f\u503c) 3. Z-score: \u5373\u4f7f\u7528 (\u4e2a\u4f53\u503c-\u5e73\u5747\u503c)/\u65b9\u5dee Z- score\u901a\u5e38\u5728-3\u52303\u4e4b\u95f4\u6ce2\u52a8 \u6570\u636e\u5206\u7ec4 Binning \u6570\u636e\u5206\u7ec4\u662f\u5c06\u6570\u636e\u5206\u7c7b\u5230\u4e0d\u540c\u7684\u7c7b\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u5206\u7ec4\uff0c\u53ef\u4ee5\u5c06\u6570\u636e\u5b8c\u4ece numeric -> categorical \u7684\u8f6c\u53d8\u3002\u6700\u5e38\u89c1\u7684\u4e00\u4e2a\u4f8b\u5b50\u662fgrade\u3002\u5206\u6570 90 \u4ee5\u4e0a\u5f52\u7c7b\u4e3a A\uff0c\u5206\u6570 80 \u4ee5\u4e0a\u5f52\u7c7b\u4e3a B\u3002\u901a\u8fc7\u5f52\u7c7b\u5c06\u539f\u5148 100 \u7b49\u5206 \u7684\u6210\u7ee9\u5f52\u7c7b\u5230\u4e86 A,B,C,D,F \u8fd9 \u4e94\u4e2a\u7b49\u7ea7 \u3002 # \u5212\u5206\u4e3a 3 \u5757\uff0c\u6709 4 \u6761\u7ebf bins = np . linspace ( min ( df [ \"pirce\" ]), max ( df [ \"price\" ]), 4 ) # \u4e3a\u6bcf\u4e2a\u7b49\u7ea7\u53d6\u540d group_names = [ \"low\" , \"medium\" , \"high\" ] # \u521b\u5efa\u65b0\u5217 df [ \"p-binned\" ] = pd . cut ( df [ \"price\" ], bins , labels = group_names , include_lowest = True ) Categorical -> Numeric \u90a3\u4e48\u5047\u8bbe\u6211\u4eec\u9700\u8981\u628a\u6027\u522b \u7537/\u5973 \u5206\u522b\u8f6c\u5316\u4e3a 1/0 \u5462\uff1f\u5728\u5f88\u591a\u6570\u636e\u5efa\u6a21\u548c\u6570\u636e\u5206\u6790\u4e2d\uff0c\u6570\u5b57\u90fd\u6bd4\u7c7b\u522b\u66f4\u597d\u5904\u7406\u3002\u4f7f\u7528 pandas \u4e2d\u7684 get_dummies() \u53ef\u4ee5\u65b9\u4fbf\u5730\u5c06\u7c7b\u522b\u8f6c\u6362\u4e3a\u6570\u5b57\u3002dummy variable \u6307\u53ea\u6709 1 or 0 \u4e24\u79cd\u8d4b\u503c\u7684\u53d8\u91cf\u3002 pd.get_dummies(df[\"fuel\"]) Python \u4e2d\u5b9e\u9645\u6570\u636e\u5904\u7406 Python \u5b9e\u9645\u7684\u6570\u636e\u9884\u5148\u5904\u7406\u53ef\u4ee5\u5206\u4e3a\u8fd9\u4e48\u51e0\u4e2a\u6b65\u9aa4 1. Handle missing data * replace missing data \u4f7f\u7528 .replace() \u66ff\u6362\u4e22\u5931\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528 mean \u6216 mode * delete missing data \u4f7f\u7528 dropna() \u5220\u9664\u5177\u6709\u9057\u5931\u6570\u636e\u7684\u884c\u6216\u5217 3. Data standardization \u6570\u636e\u6807\u51c6\u5316 4. Data normalization \u6570\u636e\u6b63\u5e38\u5316 * standardize scale \u6807\u51c6\u523b\u5ea6\u6bd4\u7387 - \u5bf9\u5217\u8fdb\u884c\u5904\u7406 * binning \u6570\u636e\u5206\u7ec4 * category -> dummy \u5728\u627e\u51fa\u9057\u5931\u6570\u636e\u7684\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u4f7f\u7528 .isnull() \u6765\u83b7\u53d6\u4e00\u4e2a\u65b0\u7684 dataframe \u5c55\u793a\u6bcf\u4e2a\u6570\u636e \u5b58\u5728/\u9057\u5931\u72b6\u6001\u3002 \u5176\u4e2d\uff0c::\u6570\u636e\u5206\u7ec4:: \u5148\u7528 bins = np.linspace(min, max, lineCount) \u6765\u5212\u5206\u51fa\u8303\u7574\uff0c\u5982\u679c\u9700\u8981\u5212\u5206 n \u4e2a\u533a\u57df\u5219\u9700\u8981 n+1 \u6761\u7ebf\u3002\u4e4b\u540e\u4f7f\u7528\u65b0\u7684 list \u53d8\u91cf\u521b\u5efa\u6bcf\u4e2a\u7ec4\u7684\u540d\u79f0\u3002\u65b0\u5efa dataframe pd.cut(columns, bins, labels=val, include-lowest=True \u6765\u5b58\u50a8\u5206\u5b8c\u7ec4\u7684\u6570\u636e\u3002 ::Category -> dummy:: \u53ef\u4ee5\u4f7f\u7528 pd.get_dummies(column) \u6765\u521b\u5efa\u65b0\u7684dataframe\u3002\u7136\u540e\u5728\u901a\u8fc7 .rename() \u628a\u5217\u540d\u6ce8\u91ca\u5730\u66f4\u6e05\u695a\u4e00\u4e9b\u3002\u4e4b\u540e\u4f7f\u7528 df = pd.concat([df, newdf], axis=1) \u628a\u65b0\u751f\u6210\u7684\u5217\u589e\u6dfb\u8fdb\u53bb\uff0c\u7136\u540e .drop() \u5220\u9664\u65e7\u7684\u3001\u4e0d\u9700\u8981\u7684\u5217\u3002","title":"\u6570\u636e\u5904\u7406"},{"location":"dataAnalysis/dataAnalysis02/#python02","text":"","title":"Python\u6570\u636e\u5206\u679002"},{"location":"dataAnalysis/dataAnalysis02/#_1","text":"\u5c06\u6570\u636e\u8fdb\u884c\u4ece\u539f\u59cb\u6570\u636e -> \u53ef\u7528\u6570\u636e\u7684\u8f6c\u6362\u3002data pre-processing \u6709\u65f6\u5019\u4e5f\u88ab\u79f0\u4e3a\u6570\u636e\u6e05\u6d17\uff08data cleaning\uff09\u6216data wrangling\u3002 handle missing value \u627e\u51fa\u5e76\u5904\u7406\u9057\u5931\u7684\u6570\u636e data formating \u7edf\u4e00\u6570\u636e\u683c\u5f0f data normalization \u6807\u51c6\u5316\u6570\u636e (centering / scaling) \u786e\u5b9a\u4f7f\u7528\u7684\u6570\u636e\u8303\u7574 data binning \u6570\u636e\u5206\u7ec4","title":"\u6570\u636e\u9884\u5148\u5904\u7406"},{"location":"dataAnalysis/dataAnalysis02/#_2","text":"\u901a\u5e38\u6765\u8bf4\u9057\u5931\u7684\u6570\u636e\u8868\u73b0\u5f62\u5f0f\u4e3a \u201c?\u201d \u201cN?A\u201d 0 \u6216\u8005\u7a7a\u767d\u3002\u6709\u4ee5\u4e0b\u51e0\u79cd\u5904\u7406\u65b9\u5f0f 1. \u67e5\u770b\u6570\u636e\u7684\u6570\u636e\u6e90\uff0c\u786e\u4fdd\u6e90\u5934\u6570\u636e\u7684\u5b8c\u6574\u6027\u548c\u53ca\u65f6\u6027 2. \u79fb\u9664\u6570\u636e\uff08\u79fb\u9664\u5355\u4e2a\u6570\u636e \u6216 \u79fb\u9664\u6574\u4e2a\u53d8\u91cf\uff09 3. \uff08\u4f7f\u7528\u5e73\u5747\u503c/mode\u503c\uff09\u66ff\u6362\u9057\u5931\u7684\u6570\u636e\uff0c\u4f46\u8be5\u79cd\u505a\u6cd5\u4f1a\u964d\u4f4e\u6570\u636e\u7684\u51c6\u786e\u6027","title":"\u5904\u7406\u9057\u5931\u7684\u6570\u636e"},{"location":"dataAnalysis/dataAnalysis02/#_3","text":"\u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 dataframes.dropna() \u65b9\u6cd5\u3002 * axis=0 \u5220\u9664\u51fa\u73b0\u7a7a\u767d\u503c\u7684\u6574\u884c * axis=1 \u5220\u9664\u51fa\u73b0\u7a7a\u767d\u503c\u7684\u6574\u5217\u3002 \u4e00\u4e2a\u793a\u4f8b\u4e3a df.dropna(subset=[\"price'], axis=0, inplace=True) \u3002","title":"\u5220\u9664\u9057\u5931\u503c"},{"location":"dataAnalysis/dataAnalysis02/#_4","text":"\u53ef\u4ee5\u4f7f\u7528 df.replace(missing_value, new_value) \u3002\u73b0\u5728\u5047\u8bbe\u6211\u4eec\u60f3\u8981\u7528\u8be5\u5217\u7684\u5e73\u5747\u503c\u6765\u66ff\u6362\u6389\u51fa\u73b0\u7684\u9057\u5931\u503c\u3002 # \u8ba1\u7b97\u51fa\u8be5\u5217\u7684\u5e73\u5747\u503c mean = df [ \"normalized-losses\" ] . mean () # \u9650\u5b9a\u4f5c\u7528\u8303\u7574\u7684\u5217\uff0c\u518d\u4f7f\u7528 df.replace() \u65b9\u6cd5 df [ \"normalized-losses\" ] . replace ( np . nan , mean )","title":"\u66ff\u6362\u9057\u5931\u503c"},{"location":"dataAnalysis/dataAnalysis02/#data-standardization","text":"\u6570\u636e\u901a\u5e38\u7531\u591a\u4eba\u4ece\u4e0d\u540c\u6e20\u9053\u6536\u96c6\uff0c\u5e76\u4e14\u4ee5\u591a\u6837\u7684\u5f62\u5f0f\u4fdd\u5b58\u3002\u7edf\u4e00\u6570\u636e\u683c\u5f0f\u4f1a\u4e3a\u4e4b\u540e\u7684\u6570\u636e\u5206\u6790\u5e26\u6765\u5f88\u5927\u7684\u4fbf\u5229\u3002\u5728\u5f88\u591a\u91d1\u79d1\u4f01\u4e1a\u548c\u91d1\u63a7\u516c\u53f8\u4e2d\u4e5f\u5728\u4e0d\u65ad\u63d0\u5021\u7edf\u4e00\u6570\u636e\u683c\u5f0f\uff0c\u4e5f\u79f0\u4f5c \u6570\u636e\u6cbb\u7406 \u3002 \u4ee5\u4e0a\u7684\u793a\u4f8b\u5c55\u793a\u4e86\u6570\u636e-\u4eba\u5458\u7684\u57ce\u5e02\u53ef\u4ee5\u8868\u73b0\u4e3a \u201cNew York\u201d \u201cNY\u201d \u6216\u8005 \u201cN.Y\u201d\uff0c\u5728\u8fd9\u79cd\u573a\u666f\u4e0b\u9700\u8981\u7edf\u4e00\u5176\u6570\u636e\u683c\u5f0f\u3002 \u8fd8\u6709\u4e00\u79cd\u573a\u666f\u662f\u5c06\u6570\u636e\u8f6c\u6362\u4e3a\u6700\u6613\u8bfb\u3001\u6700\u5408\u7406\u3001\u6700\u7b26\u5408\u573a\u666f\u7684\u5355\u5143\u3002\u5982\u6444\u6c0f\u5ea6\u548c\u534e\u6c0f\u5ea6\uff0c\u516c\u91cc\u548c\u82f1\u91cc\u3002\u5728\u51b3\u5b9a\u4f7f\u7528\u4ec0\u4e48\u5355\u4f4d\u7684\u65f6\u5019\u53ef\u4ee5\u8003\u8651\u4f1a\u9605\u8bfb\u8fd9\u4efd\u62a5\u544a\u3001\u53c2\u4e0e\u6570\u636e\u5206\u6790\u4eba\u5458\u7684\u60ef\u4f8b\u548c\u62a5\u544a\u7528\u9014\u3002\u5047\u8bbe\u6211\u4eec\u73b0\u5728\u9700\u8981\u5c06\u6c7d\u8f66\u7684 mpg \u8f6c\u6362\u4e3a /100km\u3002\u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 # \u8c03\u6574\u6570\u636e\u683c\u5f0f df [ \"city-mpg\" ] = 235 / [ \"city-mpg\" ] # \u91cd\u547d\u540d\u5217\u540d\uff0c\u53ef\u4ee5\u770b\u5230 columns \u53d8\u91cf\u7684\u8d4b\u503c\u6709\u70b9\u7c7b\u4f3c\u4e8e\u8bcd\u5178 # rename \u4e00\u822c\u4f7f\u7528\u4e24\u4e2a\u53c2\u6570 \u53c2\u65701\u4e3acolumns \u53c2\u65702\u4e3ainplace df . rename ( columns = { \"city_mpg\" : \"city-L/100kn\" }, inplace = True ) \u5728\u8fd9\u91cc\u9700\u8981\u5f15\u8fdb pandas \u4e2d\u7684\u6570\u636e\u7c7b\u578b\u3002\u6709 objects (\u201chello\u201d), int64 (1,3) \u548c Float64 (3.1415)\u3002\u6709\u65f6\u5019\u5f53\u6211\u4eec\u8c03\u6574\u6570\u636e\u7c7b\u578b\u65f6\u4f1a\u53d1\u751f\u6570\u636e\u7c7b\u578b\u548c\u8c03\u6574\u540e\u7684\u6570\u636e\u4e0d\u5339\u914d\u7684\u60c5\u51b5\u3002 \u4f7f\u7528 df.dtypes() \u53ef\u4ee5\u67e5\u8be2\u6570\u636e\u7c7b\u578b \u4f7f\u7528 df.astype() \u53ef\u4ee5\u8f6c\u6362\u6570\u636e\u7c7b\u578b\uff0c\u5982 df[\"price\"] = df[\"price].astype(\"float\")","title":"\u7edf\u4e00\u3001\u5408\u7406\u7684\u6570\u636e\u683c\u5f0f Data Standardization"},{"location":"dataAnalysis/dataAnalysis02/#data-normalization","text":"\u60f3\u8c61\u4e00\u4e2a\u4f8b\u5b50\uff0c\u4e00\u4e2a\u6d4b\u8bd5\u6536\u96c6\u4e86\u88ab\u8bd5\u8005\u7684\u5e74\u9f84\u548c\u6536\u5165\uff0c\u5e74\u9f84\u7684\u8303\u7574\u4f1a\u572810-100\u95f4\u6ce2\u52a8\uff0c\u4f46\u662f\u6536\u5165\u7684\u6ce2\u52a8\u8303\u7574\u4f1a\u8fdc\u8fdc\u5927\u4e8e\u5e74\u9f84\uff0c\u57282,000-200,000\u6ce2\u52a8\u3002\u8fd9\u6837\u6536\u5165\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\u4f1a\u8fdc\u8fdc\u5927\u4e8e\u5e74\u9f84\u7684\u5bf9\u7ed3\u679c\u7684\u5f71\u54cd\uff0c\u5373\u7ed3\u679c\u4f1a\u6709\u504f\u5dee\u3002 \u6709\u4ee5\u4e0b\u51e0\u79cd\u65b9\u5f0f\u53ef\u4ee5\u89e3\u51b3\u6570\u636e\u6bd4\u4f8b\u7684\u95ee\u9898 1. Simple feature scaling: \u5373\u4f7f\u7528 \u4e2a\u4f53\u503c/\u6700\u5927\u503c 2. Min-Max: \u5373\u4f7f\u7528 (\u4e2a\u4f53\u503c-\u6700\u5c0f\u503c) / (\u6700\u5927\u503c-\u6700\u5c0f\u503c) 3. Z-score: \u5373\u4f7f\u7528 (\u4e2a\u4f53\u503c-\u5e73\u5747\u503c)/\u65b9\u5dee Z- score\u901a\u5e38\u5728-3\u52303\u4e4b\u95f4\u6ce2\u52a8","title":"\u6807\u51c6\u5316\u6570\u636e\u6bd4\u4f8b Data Normalization"},{"location":"dataAnalysis/dataAnalysis02/#binning","text":"\u6570\u636e\u5206\u7ec4\u662f\u5c06\u6570\u636e\u5206\u7c7b\u5230\u4e0d\u540c\u7684\u7c7b\u7684\u884c\u4e3a\uff0c\u901a\u8fc7\u5206\u7ec4\uff0c\u53ef\u4ee5\u5c06\u6570\u636e\u5b8c\u4ece numeric -> categorical \u7684\u8f6c\u53d8\u3002\u6700\u5e38\u89c1\u7684\u4e00\u4e2a\u4f8b\u5b50\u662fgrade\u3002\u5206\u6570 90 \u4ee5\u4e0a\u5f52\u7c7b\u4e3a A\uff0c\u5206\u6570 80 \u4ee5\u4e0a\u5f52\u7c7b\u4e3a B\u3002\u901a\u8fc7\u5f52\u7c7b\u5c06\u539f\u5148 100 \u7b49\u5206 \u7684\u6210\u7ee9\u5f52\u7c7b\u5230\u4e86 A,B,C,D,F \u8fd9 \u4e94\u4e2a\u7b49\u7ea7 \u3002 # \u5212\u5206\u4e3a 3 \u5757\uff0c\u6709 4 \u6761\u7ebf bins = np . linspace ( min ( df [ \"pirce\" ]), max ( df [ \"price\" ]), 4 ) # \u4e3a\u6bcf\u4e2a\u7b49\u7ea7\u53d6\u540d group_names = [ \"low\" , \"medium\" , \"high\" ] # \u521b\u5efa\u65b0\u5217 df [ \"p-binned\" ] = pd . cut ( df [ \"price\" ], bins , labels = group_names , include_lowest = True )","title":"\u6570\u636e\u5206\u7ec4 Binning"},{"location":"dataAnalysis/dataAnalysis02/#categorical-numeric","text":"\u90a3\u4e48\u5047\u8bbe\u6211\u4eec\u9700\u8981\u628a\u6027\u522b \u7537/\u5973 \u5206\u522b\u8f6c\u5316\u4e3a 1/0 \u5462\uff1f\u5728\u5f88\u591a\u6570\u636e\u5efa\u6a21\u548c\u6570\u636e\u5206\u6790\u4e2d\uff0c\u6570\u5b57\u90fd\u6bd4\u7c7b\u522b\u66f4\u597d\u5904\u7406\u3002\u4f7f\u7528 pandas \u4e2d\u7684 get_dummies() \u53ef\u4ee5\u65b9\u4fbf\u5730\u5c06\u7c7b\u522b\u8f6c\u6362\u4e3a\u6570\u5b57\u3002dummy variable \u6307\u53ea\u6709 1 or 0 \u4e24\u79cd\u8d4b\u503c\u7684\u53d8\u91cf\u3002 pd.get_dummies(df[\"fuel\"])","title":"Categorical -&gt; Numeric"},{"location":"dataAnalysis/dataAnalysis02/#python","text":"Python \u5b9e\u9645\u7684\u6570\u636e\u9884\u5148\u5904\u7406\u53ef\u4ee5\u5206\u4e3a\u8fd9\u4e48\u51e0\u4e2a\u6b65\u9aa4 1. Handle missing data * replace missing data \u4f7f\u7528 .replace() \u66ff\u6362\u4e22\u5931\u7684\u6570\u636e\uff0c\u53ef\u4ee5\u4f7f\u7528 mean \u6216 mode * delete missing data \u4f7f\u7528 dropna() \u5220\u9664\u5177\u6709\u9057\u5931\u6570\u636e\u7684\u884c\u6216\u5217 3. Data standardization \u6570\u636e\u6807\u51c6\u5316 4. Data normalization \u6570\u636e\u6b63\u5e38\u5316 * standardize scale \u6807\u51c6\u523b\u5ea6\u6bd4\u7387 - \u5bf9\u5217\u8fdb\u884c\u5904\u7406 * binning \u6570\u636e\u5206\u7ec4 * category -> dummy \u5728\u627e\u51fa\u9057\u5931\u6570\u636e\u7684\u8fc7\u7a0b\u4e2d\uff0c\u53ef\u4ee5\u6709\u6548\u4f7f\u7528 .isnull() \u6765\u83b7\u53d6\u4e00\u4e2a\u65b0\u7684 dataframe \u5c55\u793a\u6bcf\u4e2a\u6570\u636e \u5b58\u5728/\u9057\u5931\u72b6\u6001\u3002 \u5176\u4e2d\uff0c::\u6570\u636e\u5206\u7ec4:: \u5148\u7528 bins = np.linspace(min, max, lineCount) \u6765\u5212\u5206\u51fa\u8303\u7574\uff0c\u5982\u679c\u9700\u8981\u5212\u5206 n \u4e2a\u533a\u57df\u5219\u9700\u8981 n+1 \u6761\u7ebf\u3002\u4e4b\u540e\u4f7f\u7528\u65b0\u7684 list \u53d8\u91cf\u521b\u5efa\u6bcf\u4e2a\u7ec4\u7684\u540d\u79f0\u3002\u65b0\u5efa dataframe pd.cut(columns, bins, labels=val, include-lowest=True \u6765\u5b58\u50a8\u5206\u5b8c\u7ec4\u7684\u6570\u636e\u3002 ::Category -> dummy:: \u53ef\u4ee5\u4f7f\u7528 pd.get_dummies(column) \u6765\u521b\u5efa\u65b0\u7684dataframe\u3002\u7136\u540e\u5728\u901a\u8fc7 .rename() \u628a\u5217\u540d\u6ce8\u91ca\u5730\u66f4\u6e05\u695a\u4e00\u4e9b\u3002\u4e4b\u540e\u4f7f\u7528 df = pd.concat([df, newdf], axis=1) \u628a\u65b0\u751f\u6210\u7684\u5217\u589e\u6dfb\u8fdb\u53bb\uff0c\u7136\u540e .drop() \u5220\u9664\u65e7\u7684\u3001\u4e0d\u9700\u8981\u7684\u5217\u3002","title":"Python \u4e2d\u5b9e\u9645\u6570\u636e\u5904\u7406"},{"location":"dataAnalysis/dataAnalysis03/","text":"Python\u6570\u636e\u5206\u679003 \u6570\u636e\u63a2\u7d22 Exploratory Data Analysis (EDA) \u5206\u6790\u6570\u636e\u7684\u4e3b\u8981\u7279\u70b9 \u63d0\u5347\u5bf9\u6570\u636e\u7684\u8ba4\u77e5 \u6316\u6398\u6570\u636e\u53d8\u91cf\u95f4\u7684\u5173\u7cfb \u627e\u51fa\u91cd\u8981\u7684\u53d8\u91cf \u5728\u8fd9\u4e2a\u7ae0\u8282\u4e2d\u6211\u4eec\u4f1a\u5b66\u4e60: Descriptive Statistics \u63cf\u8ff0\u6027\u7edf\u8ba1 GroupBy \u6570\u636e\u900f\u89c6\u8868 Correlation \u6570\u636e\u5173\u8054 Correlation - Statistics \u63cf\u8ff0\u6027\u7edf\u8ba1 Descriptive Statistics \u63cf\u8ff0\u6570\u636e\u7684\u57fa\u672c\u7279\u5f81 \u7b80\u660e\u627c\u8981\u5730\u63cf\u8ff0\u6570\u636e\u6837\u672c \u63cf\u8ff0\u6027\u7edf\u8ba1\u91c7\u7528\u7684\u65b9\u6cd5 df.describe() \u4f1a\u8fd4\u56de\u8ba1\u6570\u3001\u5e73\u5747\u6570\u3001\u6700\u5927\u6700\u5c0f\u503c\u7b49\uff0c\u901a\u8fc7\u4f7f\u7528\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5f88\u660e\u6670\u5730\u6d1e\u5bdf\u6570\u636e\u7684\u5206\u5e03\u3002 df.value_counts() \u4f1a\u5448\u73b0\u5206\u7c7b\u53d8\u91cf\u7684\u5404\u79cd\u6570\u503c\u548c\u8ba1\u6570\u3002\u5206\u7c7b\u53d8\u91cf categorical data \u6307\u503c\u662f\u5404\u79cd\u5206\u7c7b\uff0c\u5982 medium / high / low\u3002 ::Box Plots \u7bb1\u5f62\u56fe:: \u6709\u70b9\u7c7b\u4f3c\u4e8e\u80a1\u7968\u4e2d\u7684K\u7ebf\uff0c\u4ee5\u53ef\u89c6\u5316\u7684\u65b9\u5f0f\u5448\u73b0\u6700\u9ad8\u503c\u3001\u6700\u4f4e\u503c\u3001medium\u3001\u548c\u5404\u7c7bpercentile\u3002\u5728 python \u901a\u8fc7\u8c03\u7528 sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df) \u6765\u5b9e\u73b0\u3002 ==Scatter Plots \u6563\u70b9\u56fe== \u4f1a\u5c06\u6bcf\u4e2a\u6570\u636e\u4ee5\u4e00\u4e2a\u70b9\u7684\u5f62\u5f0f\u5448\u73b0\u51fa\u6765\u3002\u6563\u6b65\u56fe\u53ef\u4ee5 \u6709\u6548\u5730\u89e3\u91ca\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb \u3002 * predictor / independent variable on x-axis * target / dependent variables on y-axis x = df [ \"engine-size\" ] y = df [ \"price\" ] plt . scatter ( x , y ) plt . title ( \"Engine Size vs Price\" ) plt . xlabel ( \"Engine Size\" ) plt . ylabel ( \"Price\" ) \u805a\u5408 GroupBy Python \u4e2d\u7684\u805a\u5408\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 dataframe.Groupby() \u65b9\u6cd5\u6765\u5b9e\u73b0\uff0c\u5176\u4f5c\u7528\u5bf9\u8c61\u4e3a\u5206\u7c7b\u53d8\u91cf\uff0c\u53ef\u4ee5\u5305\u62ec\u4e00\u4e2a\u6216\u591a\u4e2a\u53d8\u91cf\u3002 df_test = df [[ \"drive_wheel\" , \"body_style\" , \"price\" ]] # group by drive wheel and body style df_grp = df_test . groupby ([ \"drive_wheel\" , \"body-style\" ], as_index = False ) . mean () ::pivot \u6570\u636e\u900f\u89c6\u8868:: \u5728\u4e0a\u8ff0\u7ed3\u679c\u7684\u57fa\u7840\u4e0a\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528 pivot() \u65b9\u6cd5\u6765\u5c06\u7ed3\u679c\u53ef\u89c6\u5316\u3002\u6570\u636e\u900f\u89c6\u8868\u4f1a\u628a\u4e00\u4e2a\u53d8\u91cf\u653e\u5728\u5217\u4e0a\uff0c\u53e6\u4e00\u4e2a\u53d8\u91cf\u653e\u5728\u884c\u4e0a\u3002 df_pivot = df_grp . pivot ( index = \"drive-wheels\" , columns = \"body-style\" ) ::heat map \u70ed\u529b\u56fe:: \u9664\u6570\u636e\u900f\u89c6\u8868\u5916\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528\u70ed\u529b\u56fe\u6765\u5206\u6790\u5404\u4e2a\u56e0\u7d20\u5bf9\u76ee\u6807\u53d8\u91cf\u7684\u5f71\u54cd\u3002 plt . pcolor ( df_pivot , cmap = 'RdBu' ) plt . colorbar () plt . show () \u6570\u636e\u5173\u8054 Correlation \u5173\u8054\u6027 \u7684\u5b9a\u4e49\u4e3a\u5728\u4f55\u79cd\u7a0b\u5ea6\u4e0a\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u4f9d\u8d56\u3002\u4e3e\u4f8b\u6765\u8bf4\uff0c\u5438\u70df\u7684\u7a0b\u5ea6\u548c\u80ba\u764c\u5177\u6709\u4e00\u5b9a\u7684\u5173\u8054\uff0c\u5438\u70df\u8d8a\u591a\u3001\u60a3\u80ba\u764c\u7684\u51e0\u7387\u8d8a\u9ad8\u3002 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 sns.regplot \u6765\u68c0\u9a8c\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u8054\u3002::regplot:: \u4e3a regression plot \u7684\u7f29\u5199\u3002 sns . regplot ( x = \"engine-size\" , y = \"price\" , data = df ) plt . ylim ( 0 ,) Correlation \u5206\u4e3a positive correlation \u548c negative correlation\u3002\u524d\u8005\u968f\u7740independent variable \u53d8\u5927 dependent variable \u53d8\u5927\uff0c\u540e\u8005\u5219\u76f8\u53cd\u3002\u4e0a\u8ff0\u56fe\u4e3a positive correlation\u3002 \u7edf\u8ba1\u5b66\u4e2d\u7684\u5173\u8054 correlation coefficient and p-value ::\u5206\u6790\u5173\u8054\u6027\u7684\u5f3a\u5ea6 strength of the correlation:: * correlation coefficient \u76f8\u5173\u7cfb\u6570 * p-value \u5f53\u76f8\u5173\u7cfb\u6570 * \u8d8a\u63a5\u8fd1 1\uff0c\u5219\u5176\u8d8a\u5177\u6709\u6b63\u5411\u7684\u76f8\u5173\u5173\u7cfb * \u8d8a\u63a5\u8fd1 -1\uff0c\u5219\u5176\u8d8a\u5177\u6709\u53cd\u5411\u7684\u76f8\u5173\u5173\u7cfb * \u8d8a\u63a5\u8fd10\uff0c\u8bf4\u660e\u5176\u4e0d\u5177\u6709\u76f8\u5173\u5173\u7cfb \u5f53 p-value * p-value < 0.001 \u975e\u5e38\u5f3a\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value < 0.05 \u9002\u4e2d\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value < 0.1 \u5f31\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value > 0.1 \u7ed3\u679c\u4e0d\u5177\u6709\u53ef\u786e\u6027 \u5f3a\u5173\u8054\u9700\u8981\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\u3002 1. \u76f8\u5173\u7cfb\u6570\u975e\u5e38\u63a5\u8fd1 1 \u6216 -1 2. p-value < 0.001 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528\u4e00\u884c\u4ee3\u7801\u6765\u83b7\u53d6\u76f8\u5173\u7cfb\u6570\u548cp-value\u3002 pearson_coef , p_value = stats . pearsonr ( df [ 'horsepower' , df [ 'price' ]) \u4e0a\u8ff0\u7684\u70ed\u529b\u56fe\u662f 17 * 17 \u7684\u4e00\u4e2a\u65b9\u9635\uff0c\u63ed\u793a\u4e86\u6bcf\u4e2a\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u7684\u5173\u7cfb\u3002\u989c\u8272\u8d8a\u6df1\uff08\u6df1\u7ea2\u6216\u6df1\u84dd\uff09\u4ee3\u8868\u5176\u5173\u8054\u7cfb\u6570\u8d8a\u9ad8\u3002\u659c\u7ebf\u56e0\u4e3a\u662f\u548c\u81ea\u5df1\u6bd4\u8f83\uff0c\u6240\u4ee5\u5173\u8054\u7cfb\u6570\u4e00\u5b9a\u4e3a1\uff0c\u6545\u989c\u8272\u4e00\u5b9a\u6700\u6df1\u3002 \u5361\u65b9\u68c0\u9a8c Chi-square Correlation coefficient \u548c p-value \u4e3b\u8981\u670d\u52a1\u4e8e continuous variable\u3002\u5f53\u53d8\u91cf\u4e3a categorical variable \u5373 \u5206\u7c7b\u53d8\u91cf\u65f6\uff0c\u662f\u65f6\u5019\u63a8\u51fa chi-square \u5361\u65b9\u68c0\u9a8c\u4e86 \u3002 \u5361\u65b9\u68c0\u9a8c\u7528\u6765\u5224\u65ad\u5728\u4f55\u79cd\u7a0b\u5ea6\u4e0a\u89c2\u6d4b\u5230\u7684\u5206\u5e03\u7b26\u5408\u9884\u5148\u7684\u731c\u6d4b\u3002\u5361\u65b9\u68c0\u9a8c\u4e0d\u4f1a\u544a\u77e5\u53d8\u91cf\u95f4\u5b58\u5728\u7684\u662f\u4f55\u79cd\u5173\u7cfb\uff0c\u4f46\u662f\u5176\u4f1a\u544a\u77e5\u53d8\u91cf\u95f4 \u662f\u5426\u5b58\u5728\u5173\u7cfb \u3002 \u4e0b\u9762\u4ee5\u4e00\u4e2a\u5177\u4f53\u7684\u5b9e\u4f8b\u6765\u6f14\u793a\u5361\u65b9\u68c0\u9a8c\u7684\u6d41\u7a0b\uff1a 1. \u63a8\u51fa null hypothesis: \u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u4e0d\u5b58\u5728\u5173\u7cfb 2. \u4f7f\u7528 pandas \u7684 cross-tab \u6765\u663e\u793a category variable \u4e4b\u95f4\u7684\u5206\u5e03\u5173\u7cfb 3. \u901a\u8fc7\u516c\u5f0f\u8ba1\u7b97\u51fachi-square\u7684\u503c\uff0c\u5e76\u5bf9\u7167 percentage points of chi-square distribution \u6765\u68c0\u9a8c\u5176 p-value 4. \u8bc1\u5b9e\u6216\u56de\u7edd null hypothesis \u5728 python \u4e2d\u53ef\u4f7f\u7528 scipy \u6765\u5b9e\u73b0\u5361\u65b9\u68c0\u9a8c\uff0c\u4e14python\u4f1a \u7ed9\u51fa\u5177\u4f53\u7684p-value\u503c \u3002 scipy . stats . chi2_contingency ( cont_table , correction = True ) \u7b2c\u4e00\u4e2a\u503c\u4e3achi-square\u503c\uff0c\u7b2c\u4e8c\u4e2a\u4e3ap-value\uff08\u53ef\u4ee5\u660e\u663e\u770b\u5230\u5176\u5c0f\u4e8e0.05) \uff0c\u7b2c\u4e09\u4e2a\u503c\u4e3a degree of freedom\uff0c\u7b2c\u56db\u4e2a\u4e3a\u5404\u4e2a\u5206\u7c7b\u53d8\u91cf\u7ec4\u5408\u7684\u9884\u8ba1\u503c\u3002\u56e0\u4e3a\u5176p-value\u663e\u8457\u5c0f\u4e8e0.05\uff0c\u5219\u5426\u51b3\u4e86\u4e00\u5f00\u59cb\u7684null hypothesis\uff0c\u5373\u8bf4\u660e\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u5173\u8054\u6027\u3002","title":"\u6570\u636e\u5206\u6790"},{"location":"dataAnalysis/dataAnalysis03/#python03","text":"","title":"Python\u6570\u636e\u5206\u679003"},{"location":"dataAnalysis/dataAnalysis03/#_1","text":"Exploratory Data Analysis (EDA) \u5206\u6790\u6570\u636e\u7684\u4e3b\u8981\u7279\u70b9 \u63d0\u5347\u5bf9\u6570\u636e\u7684\u8ba4\u77e5 \u6316\u6398\u6570\u636e\u53d8\u91cf\u95f4\u7684\u5173\u7cfb \u627e\u51fa\u91cd\u8981\u7684\u53d8\u91cf \u5728\u8fd9\u4e2a\u7ae0\u8282\u4e2d\u6211\u4eec\u4f1a\u5b66\u4e60: Descriptive Statistics \u63cf\u8ff0\u6027\u7edf\u8ba1 GroupBy \u6570\u636e\u900f\u89c6\u8868 Correlation \u6570\u636e\u5173\u8054 Correlation - Statistics","title":"\u6570\u636e\u63a2\u7d22"},{"location":"dataAnalysis/dataAnalysis03/#descriptive-statistics","text":"\u63cf\u8ff0\u6570\u636e\u7684\u57fa\u672c\u7279\u5f81 \u7b80\u660e\u627c\u8981\u5730\u63cf\u8ff0\u6570\u636e\u6837\u672c \u63cf\u8ff0\u6027\u7edf\u8ba1\u91c7\u7528\u7684\u65b9\u6cd5 df.describe() \u4f1a\u8fd4\u56de\u8ba1\u6570\u3001\u5e73\u5747\u6570\u3001\u6700\u5927\u6700\u5c0f\u503c\u7b49\uff0c\u901a\u8fc7\u4f7f\u7528\u8be5\u65b9\u6cd5\u53ef\u4ee5\u5f88\u660e\u6670\u5730\u6d1e\u5bdf\u6570\u636e\u7684\u5206\u5e03\u3002 df.value_counts() \u4f1a\u5448\u73b0\u5206\u7c7b\u53d8\u91cf\u7684\u5404\u79cd\u6570\u503c\u548c\u8ba1\u6570\u3002\u5206\u7c7b\u53d8\u91cf categorical data \u6307\u503c\u662f\u5404\u79cd\u5206\u7c7b\uff0c\u5982 medium / high / low\u3002 ::Box Plots \u7bb1\u5f62\u56fe:: \u6709\u70b9\u7c7b\u4f3c\u4e8e\u80a1\u7968\u4e2d\u7684K\u7ebf\uff0c\u4ee5\u53ef\u89c6\u5316\u7684\u65b9\u5f0f\u5448\u73b0\u6700\u9ad8\u503c\u3001\u6700\u4f4e\u503c\u3001medium\u3001\u548c\u5404\u7c7bpercentile\u3002\u5728 python \u901a\u8fc7\u8c03\u7528 sns.boxplot(x=\"drive-wheels\", y=\"price\", data=df) \u6765\u5b9e\u73b0\u3002 ==Scatter Plots \u6563\u70b9\u56fe== \u4f1a\u5c06\u6bcf\u4e2a\u6570\u636e\u4ee5\u4e00\u4e2a\u70b9\u7684\u5f62\u5f0f\u5448\u73b0\u51fa\u6765\u3002\u6563\u6b65\u56fe\u53ef\u4ee5 \u6709\u6548\u5730\u89e3\u91ca\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb \u3002 * predictor / independent variable on x-axis * target / dependent variables on y-axis x = df [ \"engine-size\" ] y = df [ \"price\" ] plt . scatter ( x , y ) plt . title ( \"Engine Size vs Price\" ) plt . xlabel ( \"Engine Size\" ) plt . ylabel ( \"Price\" )","title":"\u63cf\u8ff0\u6027\u7edf\u8ba1 Descriptive Statistics"},{"location":"dataAnalysis/dataAnalysis03/#groupby","text":"Python \u4e2d\u7684\u805a\u5408\u53ef\u4ee5\u901a\u8fc7\u4f7f\u7528 dataframe.Groupby() \u65b9\u6cd5\u6765\u5b9e\u73b0\uff0c\u5176\u4f5c\u7528\u5bf9\u8c61\u4e3a\u5206\u7c7b\u53d8\u91cf\uff0c\u53ef\u4ee5\u5305\u62ec\u4e00\u4e2a\u6216\u591a\u4e2a\u53d8\u91cf\u3002 df_test = df [[ \"drive_wheel\" , \"body_style\" , \"price\" ]] # group by drive wheel and body style df_grp = df_test . groupby ([ \"drive_wheel\" , \"body-style\" ], as_index = False ) . mean () ::pivot \u6570\u636e\u900f\u89c6\u8868:: \u5728\u4e0a\u8ff0\u7ed3\u679c\u7684\u57fa\u7840\u4e0a\uff0c\u8fd8\u53ef\u4ee5\u4f7f\u7528 pivot() \u65b9\u6cd5\u6765\u5c06\u7ed3\u679c\u53ef\u89c6\u5316\u3002\u6570\u636e\u900f\u89c6\u8868\u4f1a\u628a\u4e00\u4e2a\u53d8\u91cf\u653e\u5728\u5217\u4e0a\uff0c\u53e6\u4e00\u4e2a\u53d8\u91cf\u653e\u5728\u884c\u4e0a\u3002 df_pivot = df_grp . pivot ( index = \"drive-wheels\" , columns = \"body-style\" ) ::heat map \u70ed\u529b\u56fe:: \u9664\u6570\u636e\u900f\u89c6\u8868\u5916\uff0c\u6211\u4eec\u4e5f\u53ef\u4ee5\u4f7f\u7528\u70ed\u529b\u56fe\u6765\u5206\u6790\u5404\u4e2a\u56e0\u7d20\u5bf9\u76ee\u6807\u53d8\u91cf\u7684\u5f71\u54cd\u3002 plt . pcolor ( df_pivot , cmap = 'RdBu' ) plt . colorbar () plt . show ()","title":"\u805a\u5408 GroupBy"},{"location":"dataAnalysis/dataAnalysis03/#_2","text":"Correlation \u5173\u8054\u6027 \u7684\u5b9a\u4e49\u4e3a\u5728\u4f55\u79cd\u7a0b\u5ea6\u4e0a\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u4f9d\u8d56\u3002\u4e3e\u4f8b\u6765\u8bf4\uff0c\u5438\u70df\u7684\u7a0b\u5ea6\u548c\u80ba\u764c\u5177\u6709\u4e00\u5b9a\u7684\u5173\u8054\uff0c\u5438\u70df\u8d8a\u591a\u3001\u60a3\u80ba\u764c\u7684\u51e0\u7387\u8d8a\u9ad8\u3002 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 sns.regplot \u6765\u68c0\u9a8c\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u8054\u3002::regplot:: \u4e3a regression plot \u7684\u7f29\u5199\u3002 sns . regplot ( x = \"engine-size\" , y = \"price\" , data = df ) plt . ylim ( 0 ,) Correlation \u5206\u4e3a positive correlation \u548c negative correlation\u3002\u524d\u8005\u968f\u7740independent variable \u53d8\u5927 dependent variable \u53d8\u5927\uff0c\u540e\u8005\u5219\u76f8\u53cd\u3002\u4e0a\u8ff0\u56fe\u4e3a positive correlation\u3002","title":"\u6570\u636e\u5173\u8054"},{"location":"dataAnalysis/dataAnalysis03/#correlation-coefficient-and-p-value","text":"::\u5206\u6790\u5173\u8054\u6027\u7684\u5f3a\u5ea6 strength of the correlation:: * correlation coefficient \u76f8\u5173\u7cfb\u6570 * p-value \u5f53\u76f8\u5173\u7cfb\u6570 * \u8d8a\u63a5\u8fd1 1\uff0c\u5219\u5176\u8d8a\u5177\u6709\u6b63\u5411\u7684\u76f8\u5173\u5173\u7cfb * \u8d8a\u63a5\u8fd1 -1\uff0c\u5219\u5176\u8d8a\u5177\u6709\u53cd\u5411\u7684\u76f8\u5173\u5173\u7cfb * \u8d8a\u63a5\u8fd10\uff0c\u8bf4\u660e\u5176\u4e0d\u5177\u6709\u76f8\u5173\u5173\u7cfb \u5f53 p-value * p-value < 0.001 \u975e\u5e38\u5f3a\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value < 0.05 \u9002\u4e2d\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value < 0.1 \u5f31\u7684\u7ed3\u679c\u53ef\u786e\u6027 * p-value > 0.1 \u7ed3\u679c\u4e0d\u5177\u6709\u53ef\u786e\u6027 \u5f3a\u5173\u8054\u9700\u8981\u6ee1\u8db3\u4e24\u4e2a\u6761\u4ef6\u3002 1. \u76f8\u5173\u7cfb\u6570\u975e\u5e38\u63a5\u8fd1 1 \u6216 -1 2. p-value < 0.001 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528\u4e00\u884c\u4ee3\u7801\u6765\u83b7\u53d6\u76f8\u5173\u7cfb\u6570\u548cp-value\u3002 pearson_coef , p_value = stats . pearsonr ( df [ 'horsepower' , df [ 'price' ]) \u4e0a\u8ff0\u7684\u70ed\u529b\u56fe\u662f 17 * 17 \u7684\u4e00\u4e2a\u65b9\u9635\uff0c\u63ed\u793a\u4e86\u6bcf\u4e2a\u53d8\u91cf\u4e4b\u95f4\u76f8\u4e92\u7684\u5173\u7cfb\u3002\u989c\u8272\u8d8a\u6df1\uff08\u6df1\u7ea2\u6216\u6df1\u84dd\uff09\u4ee3\u8868\u5176\u5173\u8054\u7cfb\u6570\u8d8a\u9ad8\u3002\u659c\u7ebf\u56e0\u4e3a\u662f\u548c\u81ea\u5df1\u6bd4\u8f83\uff0c\u6240\u4ee5\u5173\u8054\u7cfb\u6570\u4e00\u5b9a\u4e3a1\uff0c\u6545\u989c\u8272\u4e00\u5b9a\u6700\u6df1\u3002","title":"\u7edf\u8ba1\u5b66\u4e2d\u7684\u5173\u8054 correlation coefficient and p-value"},{"location":"dataAnalysis/dataAnalysis03/#chi-square","text":"Correlation coefficient \u548c p-value \u4e3b\u8981\u670d\u52a1\u4e8e continuous variable\u3002\u5f53\u53d8\u91cf\u4e3a categorical variable \u5373 \u5206\u7c7b\u53d8\u91cf\u65f6\uff0c\u662f\u65f6\u5019\u63a8\u51fa chi-square \u5361\u65b9\u68c0\u9a8c\u4e86 \u3002 \u5361\u65b9\u68c0\u9a8c\u7528\u6765\u5224\u65ad\u5728\u4f55\u79cd\u7a0b\u5ea6\u4e0a\u89c2\u6d4b\u5230\u7684\u5206\u5e03\u7b26\u5408\u9884\u5148\u7684\u731c\u6d4b\u3002\u5361\u65b9\u68c0\u9a8c\u4e0d\u4f1a\u544a\u77e5\u53d8\u91cf\u95f4\u5b58\u5728\u7684\u662f\u4f55\u79cd\u5173\u7cfb\uff0c\u4f46\u662f\u5176\u4f1a\u544a\u77e5\u53d8\u91cf\u95f4 \u662f\u5426\u5b58\u5728\u5173\u7cfb \u3002 \u4e0b\u9762\u4ee5\u4e00\u4e2a\u5177\u4f53\u7684\u5b9e\u4f8b\u6765\u6f14\u793a\u5361\u65b9\u68c0\u9a8c\u7684\u6d41\u7a0b\uff1a 1. \u63a8\u51fa null hypothesis: \u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u4e0d\u5b58\u5728\u5173\u7cfb 2. \u4f7f\u7528 pandas \u7684 cross-tab \u6765\u663e\u793a category variable \u4e4b\u95f4\u7684\u5206\u5e03\u5173\u7cfb 3. \u901a\u8fc7\u516c\u5f0f\u8ba1\u7b97\u51fachi-square\u7684\u503c\uff0c\u5e76\u5bf9\u7167 percentage points of chi-square distribution \u6765\u68c0\u9a8c\u5176 p-value 4. \u8bc1\u5b9e\u6216\u56de\u7edd null hypothesis \u5728 python \u4e2d\u53ef\u4f7f\u7528 scipy \u6765\u5b9e\u73b0\u5361\u65b9\u68c0\u9a8c\uff0c\u4e14python\u4f1a \u7ed9\u51fa\u5177\u4f53\u7684p-value\u503c \u3002 scipy . stats . chi2_contingency ( cont_table , correction = True ) \u7b2c\u4e00\u4e2a\u503c\u4e3achi-square\u503c\uff0c\u7b2c\u4e8c\u4e2a\u4e3ap-value\uff08\u53ef\u4ee5\u660e\u663e\u770b\u5230\u5176\u5c0f\u4e8e0.05) \uff0c\u7b2c\u4e09\u4e2a\u503c\u4e3a degree of freedom\uff0c\u7b2c\u56db\u4e2a\u4e3a\u5404\u4e2a\u5206\u7c7b\u53d8\u91cf\u7ec4\u5408\u7684\u9884\u8ba1\u503c\u3002\u56e0\u4e3a\u5176p-value\u663e\u8457\u5c0f\u4e8e0.05\uff0c\u5219\u5426\u51b3\u4e86\u4e00\u5f00\u59cb\u7684null hypothesis\uff0c\u5373\u8bf4\u660e\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u5173\u8054\u6027\u3002","title":"\u5361\u65b9\u68c0\u9a8c Chi-square"},{"location":"dataAnalysis/dataAnalysis04/","text":"Python\u6570\u636e\u5206\u679004 \u6570\u636e\u6a21\u578b \u672c\u7ae0\u8282\u4f1a\u6d89\u53ca\uff1a \u5355\u56e0\u5b50\u548c\u591a\u56e0\u5b50\u7ebf\u6027\u56de\u5f52\uff08linear regression\uff09 \u6a21\u578b\u53ef\u89c6\u5316\u548c\u8bc4\u4f30 \u591a\u9879\u5f0f\u56de\u5f52\uff08polynomial regression\uff09 \u56de\u5f52\u8bc4\u4ef7\u6307\u6807 MSE R-squared \u8bc4\u4f30\u548c\u51b3\u7b56\u5236\u5b9a \u6a21\u578b\u5728\u6b64\u7684\u5b9a\u4e49\u4e3a \u901a\u8fc7\u5206\u6790\u4e00\u4e2a\u6216\u591a\u4e2a\u56e0\u53d8\u91cf\uff0c\u5f97\u51fa\u72ec\u7acb\u53d8\u91cf \u7684\u4e00\u79cd\u65b9\u5f0f\u6216\u65b9\u6cd5\u3002\u901a\u5e38\u6765\u8bf4\u56e0\u53d8\u91cf\u5173\u8054\u6027\u8d8a\u5f3a\uff0c\u6700\u540e\u5f97\u51fa\u7684\u72ec\u7acb\u53d8\u91cf\u51c6\u786e\u6027\u8d8a\u9ad8\u3002 \u7ebf\u6027\u56de\u5f52 Linear Regression \u7ebf\u6027\u56de\u5f52\u6307\u901a\u8fc7 \u4e00\u4e2a \u56e0\u53d8\u91cf\u6765\u6d4b\u7b97\u76ee\u6807\u53d8\u91cf \u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u6307\u901a\u8fc7 \u591a\u4e2a \u56e0\u53d8\u91cf\u6765\u6d4b\u7b97\u76ee\u6807\u53d8\u91cf \u7ebf\u6027\u56de\u5f52\u7684\u901a\u7528\u516c\u5f0f\u4e3a y = b0 + b1x * b0: the intercept * b1: the slope \u901a\u5e38\uff0c\u4f1a\u5c06 x-value \u548c y-value \u5206\u522b\u50a8\u5b58\u5728\u4e24\u4e2a matrix \u5f53\u4e2d\uff0c\u5e94\u7528 python \u4e2d\u7684 numpy\u3002\u4e14 linear regression \u5f88\u96be\u5b9e\u73b0\u5b8c\u5168\u3001\u5b8c\u6574\u5730 fit\u3002\u8fd9\u91cc\u5f15\u5165 noise \u7684\u6982\u5ff5\u3002\u6d4b\u8bd5\u4eba\u5458\u4f1a\u5141\u8bb8\u4e00\u5b9a\u7684\u8bef\u5dee\uff0c\u8bef\u5dee\u53ef\u80fd\u662f\u6b63\u5411\u7684\uff0c\u4e5f\u53ef\u80fd\u662f\u8d1f\u5411\u7684\u3002\u4e14\u8bef\u5dee\u7684\u5206\u5e03\u901a\u5e38\u4e5f\u9075\u5faa\u6b63\u6001\u5206\u5e03\uff0c\u5373\u5927\u90e8\u5206\u7684\u8bef\u5dee\u63a5\u8fd1\u4e8e0\uff0c\u5c0f\u90e8\u5206\u7684\u8bef\u5dee\u8f83\u4e3a\u6781\u7aef\u3002 \u4e0a\u8ff0\u63d0\u5230\u7684\u6982\u5ff5\u53ea\u4ec5\u9650\u4e8e\u4e00\u4e2a\u72ec\u7acb\u53d8\u91cf\u3002\u4f46\u5982\u679c\u6709\u4e24\u4e2a\u3001\u4e09\u4e2a\u72ec\u7acb\u53d8\u91cf\u5462\uff1f\u4ee5\u4e24\u4e2a\u72ec\u7acb\u53d8\u91cf\u4e3a\u4f8b\uff0c\u5176\u516c\u5f0f\u4f1a\u53d8\u4e3a y = b0 + b1x1 + b2x2\u3002\u5176\u793a\u4f8b\u56fe\u4e5f\u4f1a\u53d8\u4e3a\u4e09\u7ef4\u7684\uff0c\u5982\u4e0b\u56fe\u3002 \u5728 python \u4e2d\u5e94\u7528\u7ebf\u6027\u56de\u5f52 \u4e00\u4e2a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52 # \u5bfc\u5165\u6a21\u5757 from sklearn.linear_model import LinearRegression # \u521b\u5efa\u7ebf\u6027\u56de\u5f52\u5bf9\u8c61 lm = LinearRegression () # \u786e\u5b9a x \u548c y \u7684\u503c X = df [[ 'highway-mpg' ]] Y = df [[ 'price' ]] # \u4f7f\u7528 lm.fit \u8bad\u7ec3\u6a21\u578b lm . fit ( X , Y ) # \u786e\u5b9a b0, b1 \u7684\u503c b0 , b1 = lm . intercept_ , lm . coef_ # \u521b\u5efa yhat \u7ed3\u679c\u96c6 len(x)=len(yhat) Yhat = lm . predict ( X ) # \u5e94\u7528\u6d4b\u8bd5 \u4f1a\u8fd4\u56de x [0:5] \u5bf9\u5e94\u7684 y \u503c Yhat [ 0 : 5 ] \u591a\u4e2a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52 # \u5c06\u591a\u4e2a\u53d8\u91cf\u50a8\u5b58\u5728\u5bf9\u8c61 Z \u4e2d Z = df [[ 'horsepower' , 'curb-weight' , 'engine-size' , 'highway-mpg' ]] lm . fit ( Z , df [ 'price' ]) # \u6d4b\u7b97 yhat Yhat = lm . predict ( Z ) # \u786e\u5b9ab0, b1, b2..\u7684\u503c b0 , b = lm . intercept_ , lm . coef_ # \u5176\u4e2d lm.coef_ \u7684\u5f62\u5f0f\u4e3aarray, \u5982 array([52.65, 4.70, 81.96, 33.58]) \u5176\u4e2d\uff0cY hat\u7684\u5b9a\u4e49\u4e3a: the predicted value of y (the dependent variable) in a regression equation . It can also be considered to be the average value of the response variable. The regression equation is just the equation which models the data set. \u5373\u6a21\u578b\u5728\u4e0d\u540c\u72ec\u7acb\u53d8\u91cf\u60c5\u51b5\u4e0b\u5e94\u7528\u6a21\u578b\u7684\u6d4b\u7b97\u503c\u3002 \u591a\u9879\u5f0f\u56de\u5f52 Polynomial Regression \u591a\u5143\u56de\u5f52\u4e3a\u7ebf\u6027\u56de\u5f52\u7684\u4e00\u79cd\u7279\u6b8a\u8303\u7574\uff0c\u5176\u5728\u89e3\u91ca curvilinear relationship \u65f6\u975e\u5e38\u6709\u6548\u3002 curvilinear relationship \u6307\u91c7\u7528\u67d0\u4e2a\u53d8\u91cf\u7684\u5e73\u65b9\u503c\u6216 power \u6765\u4f5c\u4e3a x-value\u3002\u591a\u5143\u56de\u5f52\u548c multiple linear regression \u7684\u4e0d\u540c\u5728\u4e8e\u524d\u8005\u662f\u6709\u4e86\u5e73\u65b9\u3001\u7acb\u65b9\u7b49\uff0c\u800c\u540e\u8005\u4ec5\u662f\u6709\u4e86\u591a\u4e2a\u72ec\u7acb\u53d8\u91cf\u3002 * quadratic - squared degree 2 * cubic - 3rd order degree 3 * higher order \u53e6\u5916\u4e00\u79cd\u65b9\u5f0f\u662f\u4f7f\u7528 Pipelines\u3002Pipeline \u53ef\u4ee5\u6709\u6548\u7b80\u5316\u6a21\u578b\u5efa\u6a21\u7684\u6b65\u9aa4\u3002\u5982\u4e0b\u56fe\uff0c\u5305\u62ec\u4e86 3 \u4e2a\u6b65\u9aa4\uff0c\u6570\u636e\u6b63\u5e38\u5316\u3001\u591a\u9879\u5f0f\u56de\u5f52\u8f6c\u6362\u3001\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u6700\u540e\u8fd4\u56de yhat\u3002 \u5728 python \u4e2d\u5b9e\u73b0\u591a\u9879\u5f0f\u56de\u5f52 f = np . polyfit ( x , y , 3 ) # \u4f7f\u7528 poly1d \u8f6c\u6362\u4e3a\u516c\u5f0f p = np . poly1d ( f ) print ( p ) print ( np . ployfit ( x , y , 3 )) # array([-1.55663829e+00, 2.04754306e+02, -8.96543312e+03, 1.37923594e+05]) # \u4f7f\u7528 preprocessing \u5e93 from sklearn.preprocessing import PolynomialFeatures # \u521b\u5efa\u4e00\u4e2a degree/order =2 \u7684\u591a\u5143\u56de\u5f52\u5bf9\u8c61 pr = PolynomialFeatures ( degree = 2 , include_bias = False ) Z_pr = pr . fit_transform ( df [[ 'horsepower' , 'curb-weight' ]]) # \u67e5\u770b\u5404\u79cd\u7ec4\u5408\uff0c\u7b2c\u4e00\u4e2a\u6570\u636e\u4e3a\u6837\u672c\u503c\uff0c\u7b2c\u4e8c\u4e2a\u4e3a feature \u503c Z_pr . shape # (201,4) ::\u4f7f\u7528 pipelines:: from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.preprocessing import StandardScaler # \u786e\u5b9a pipelien \u6b65\u9aa4 Input = [( 'scale' , StandardScaler ()), ( 'polynomial' , PolynomialFeatures ( degree = 2 )),( 'model' , LinearRegression ())] # \u521b\u5efa pipeline pipe = Pipeline ( Input ) Z = df [[ 'horsepower' , 'curb-weight' , 'engine-size' , 'highway-mpg' ]] . astype ( float ) y = df [ 'price' ] pipe . fit ( Z , y ) ypipe = pipe . predict ( Z ) ypipe [ 0 : 4 ] \u6a21\u578b\u6d4b\u8bd5\u548c\u8bc4\u4f30 \u6a21\u578b\u53ef\u89c6\u5316\u8bc4\u4f30 Model Evaluation Using Visualization \u53ef\u4ee5\u4f7f\u7528 ::regression plot:: \u6765\u4ee5\u53ef\u89c6\u5316\u5730\u65b9\u5f0f\u76f4\u89c2\u7684\u8bc4\u4f30 Linear regression \uff0cregression plot \u53ef\u4ee5\u5c55\u793a\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u548c\u5173\u8054\u7cfb\u6570\u7684\u5f3a\u5ea6\uff0c\u4ee5\u53ca\u5173\u8054\u7684\u65b9\u5411\uff08\u6b63\u5173\u8054\u3001\u8d1f\u5173\u8054\uff09\u3002 Regression plot \u662f\u6563\u70b9\u56fe\u548c\u76f4\u7ebf\u56fe\u7684\u7ed3\u5408\u3002\u6bcf\u4e2a\u70b9\u4e3a\u5355\u4e2a\u6570\u636e\uff0c\u76f4\u7ebf\u56fe\u662f\u6700\u540e\u751f\u6210\u7684\u7ebf\u6027\u56de\u5f52\u7ebf\u3002 ::Residual plot:: \u7684 y \u662f \u5b9e\u9645\u503c-\u7ebf\u6027\u56de\u5f52\u9884\u6d4b\u503c y-yhat \uff0cx \u662f\u5f53\u65f6\u4f7f\u7528\u7684 x\uff0c\u4e5f\u53ef\u4ee5\u628a\u5176\u8ba4\u4e3a\u662f\u4e00\u7ec4\u7ec4\u7684\u8bef\u5dee\u3002\u6839\u636e\u6837\u672c x \u7684\u4e0d\u65ad\u589e\u591a\uff0c\u4f1a\u7ed8\u5236\u51fa\u4e00\u526f\u8bef\u5dee/\u566a\u97f3\u7684\u56fe\u3002\u5982\u679c\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8db3\u591f\u51c6\u786e\uff0c\u8bef\u5dee\u5e94\u8be5\u662f y=0 \u7684\u4e00\u6761\u76f4\u7ebf\u3002 \u5982\u679c\u56fe\u793a\u7684\u70b9\u662f\u968f\u673a\u5206\u5e03\uff0c\u4ee3\u8868\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5177\u6709\u4e00\u5b9a\u51c6\u786e\u6027\u3002 \u7136\u800c\u5982\u679c\u56fe\u793a\u7684\u70b9\u663e\u793a\u51fa\u4e86\u4e00\u5b9a\u7684\u89c4\u5f8b\uff0c\u4ee3\u8868\u6a21\u578b\u4e0d\u591f\u51c6\u786e\u3002 ::distribution plots:: \u4f1a\u4ee5\u67f1\u5f62\u56fe\u7684\u65b9\u5f0f\u540c\u65f6\u5448\u73b0\u9884\u6d4b\u503c (y hat) \u548c\u5b9e\u9645\u503c (y) \u5728\u4e0d\u540c\u533a\u95f4\u7684\u5206\u5e03\u3002 \u4e0a\u8ff0\u4e3a\u7b80\u7ea6\u7248\u672c\u7684 distribution plot \u4e0a\u8ff0\u4e3a\u4e00\u4e2a\u6837\u672c\u8db3\u591f\u591a\u7684\u5b9e\u9645\u7248\u672c\u7684 distribution plot \u4e0a\u8ff0\u4e3a\u91c7\u7528\u5355\u5143\u548c\u591a\u5143\u7ebf\u6027\u56de\u5f52\u7684\u5dee\u5f02\u5bf9\u6bd4\uff0c\u53ef\u4ee5\u6e05\u695a\u5730\u770b\u5230\u591a\u5143\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u66f4\u52a0 fit \u5373\u66f4\u4e3a\u51c6\u786e\u3002 \u5728 python \u4e2d\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u679c import seaborn as sns # regression plot sns . regplot ( x = \"highway-mpg\" , y = \"price\" , data = df ) plt . ylim ( 0 ,) # residual plot sns . residplot ( df [ 'highway-mpg' ], df [ 'price' ]) # distribution plot # \u7ed8\u5236\u771f\u5b9e\u7684\u503c\u5206\u5e03 ax1 = sns . distplot ( df [ 'price' ], hist = False , color = 'r' , label = 'actual value' ) # \u7ed8\u5236\u6839\u636e\u6a21\u578b\u9884\u6d4b\u7684\u503c\u5206\u5e03\uff0c\u57fa\u51c6\u7ebf\u4e3a ax 1 sns . displot ( Y_hat , hist = False , color = 'b' , label = 'fitted values' , ax = ax1 ) \u6a21\u578b\u6837\u672c\u6d4b\u8bd5 In-Sample Evaluation \u6837\u672c\u6d4b\u8bd5\u53ef\u4ee5\u91cf\u5316\u8bc4\u4f30\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9002\u914d\u6027\u3002\u4e24\u79cd\u5e38\u7528\u7684\u6d4b\u8bd5\u65b9\u6cd5\u4e3a\uff1a 1. Mean Squared Error (MSE) \u5373\u8bef\u5dee\u7684\u5e73\u65b9\u603b\u548c / \u6837\u672c\u6570 2. R-squared (R^2) / coefficient of Determination \u76ee\u6807\u53d8\u91cf\u53ef\u4ee5\u7528\u6a21\u578b\u6765\u89e3\u91ca\u7684\u767e\u5206\u6bd4 R^2 = ( 1 - MSE of regression line / MSE of the average of the data) \u901a\u5e38\u6765\u8bf4\u8303\u7574\u4e3a [0,1] \u84dd\u7ebf\u4e3a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u7ea2\u7ebf\u4e3a\u6307\u5b9a\u53d8\u91cf\u7684\u5e73\u5747\u503c\u3002 \u84dd\u8272\u65b9\u5757\u4e3a\u6a21\u578b\u7684MSE\uff0c\u7ea2\u7ebf\u4e3a\u5e73\u5747\u503c\u7684MSE\u3002 \u7531\u4e0a\u56fe\u53ef\u53d1\u73b0\u84dd\u8272\u65b9\u5757\u663e\u8457\u5c0f\u4e8e\u7ea2\u8272\u65b9\u5757\uff0c\u8bc1\u5b9e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002\u5728\u6b64\u60c5\u51b5\u4e0b\uff0cMSE of regression line / MSE of y hat (\u84dd\u8272\u65b9\u5757/\u7ea2\u8272\u65b9\u5757) \u4f1a\u63a5\u8fd1\u4e8e0\u3002 # MSE from sklearn.metrics import mean_squared_error # \u7b2c\u4e00\u4e2a\u503c\u4e3a\u771f\u5b9e\u503c\uff0c\u7b2c\u4e8c\u4e2a\u503c\u4e3a\u6a21\u578b\u6d4b\u7b97\u51fa\u7684\u503c Yhat = lm . predict ( X ) mse = mean_squared_error ( df [ 'price' ], Yhat ) # R-squared X = df [[ 'highway-mpg' ]] Y = df [ 'price' ] lm . fit ( X , Y ) lm . score ( X , Y ) # R2_score from sklearn.metrics import r2_score r_squared = r2_score ( y , p ( x )) \u8bc4\u4f30\u548c\u51b3\u7b56\u5236\u5b9a \u6709\u4e0b\u5217\u51e0\u79cd\u65b9\u5f0f\u53ef\u4ee5\u8bc4\u4f30\u6a21\u578b\uff1a 1. \u6d4b\u7b97\u7684\u7ed3\u679c\u662f\u5426\u6709\u4f9d\u53ef\u5faa 2. \u53ef\u89c6\u5316\u7ed3\u679c\u5c55\u793a: residual plot, distribution plot 3. \u91cf\u5316\u8bc4\u4f30\u5206\u6790: MSE \u6216 R-squared\uff0c\u5176\u4e2d\u901a\u5e38\u6765\u8bf4 MSE \u8d8a\u5c0f\u8d8a\u597d\uff0cr-squared \u8d8a\u5927\u8d8a\u597d 4. \u6a21\u578b\u95f4\u6bd4\u8f83\u8bc4\u4f30: SLR vs. MLR, MLR vs PLR import numpy as np # arrange(x,y,z) x\u4e3a\u8d77\u59cb\u70b9 y\u4e3a\u7ec8\u7ed3\u70b9\uff0cz\u4e3a\u6b65\u6570 new_input = np . arrange ( 1 , 101 , 1 ) . reshape ( - 1 , 1 ) # \u4f7f\u7528\u6a21\u578b yhat = lm . predict ( new_input ) \u6570\u503c\u8f83\u5c0f\u7684 MSE \u662f\u5426\u4ee3\u8868\u6a21\u578b\u66f4\u9ad8\u7684\u9002\u914d\u6027\uff1f \u7b54\u6848\u5e76\u4e0d\u7edd\u5bf9\u3002\u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u7684MSE\u901a\u5e38\u4f1a\u5c0f\u4e8e\u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff08MSE for a multiple linear regression model will be smaller than the MSE for a simple linear regression model\uff09\u3002\u56e0\u4e3a\u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u7eb3\u5165\u4e86\u66f4\u591a\u7684\u6307\u5b9a\u53d8\u91cf\u3002 X variable / independent variable / explanatory variable / predictor variable Y variable / dependent variable / response variable","title":"\u6a21\u578b\u642d\u5efa\u548c\u6d4b\u8bd5"},{"location":"dataAnalysis/dataAnalysis04/#python04","text":"\u672c\u7ae0\u8282\u4f1a\u6d89\u53ca\uff1a \u5355\u56e0\u5b50\u548c\u591a\u56e0\u5b50\u7ebf\u6027\u56de\u5f52\uff08linear regression\uff09 \u6a21\u578b\u53ef\u89c6\u5316\u548c\u8bc4\u4f30 \u591a\u9879\u5f0f\u56de\u5f52\uff08polynomial regression\uff09 \u56de\u5f52\u8bc4\u4ef7\u6307\u6807 MSE R-squared \u8bc4\u4f30\u548c\u51b3\u7b56\u5236\u5b9a \u6a21\u578b\u5728\u6b64\u7684\u5b9a\u4e49\u4e3a \u901a\u8fc7\u5206\u6790\u4e00\u4e2a\u6216\u591a\u4e2a\u56e0\u53d8\u91cf\uff0c\u5f97\u51fa\u72ec\u7acb\u53d8\u91cf \u7684\u4e00\u79cd\u65b9\u5f0f\u6216\u65b9\u6cd5\u3002\u901a\u5e38\u6765\u8bf4\u56e0\u53d8\u91cf\u5173\u8054\u6027\u8d8a\u5f3a\uff0c\u6700\u540e\u5f97\u51fa\u7684\u72ec\u7acb\u53d8\u91cf\u51c6\u786e\u6027\u8d8a\u9ad8\u3002","title":"Python\u6570\u636e\u5206\u679004 \u6570\u636e\u6a21\u578b"},{"location":"dataAnalysis/dataAnalysis04/#linear-regression","text":"\u7ebf\u6027\u56de\u5f52\u6307\u901a\u8fc7 \u4e00\u4e2a \u56e0\u53d8\u91cf\u6765\u6d4b\u7b97\u76ee\u6807\u53d8\u91cf \u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u6307\u901a\u8fc7 \u591a\u4e2a \u56e0\u53d8\u91cf\u6765\u6d4b\u7b97\u76ee\u6807\u53d8\u91cf \u7ebf\u6027\u56de\u5f52\u7684\u901a\u7528\u516c\u5f0f\u4e3a y = b0 + b1x * b0: the intercept * b1: the slope \u901a\u5e38\uff0c\u4f1a\u5c06 x-value \u548c y-value \u5206\u522b\u50a8\u5b58\u5728\u4e24\u4e2a matrix \u5f53\u4e2d\uff0c\u5e94\u7528 python \u4e2d\u7684 numpy\u3002\u4e14 linear regression \u5f88\u96be\u5b9e\u73b0\u5b8c\u5168\u3001\u5b8c\u6574\u5730 fit\u3002\u8fd9\u91cc\u5f15\u5165 noise \u7684\u6982\u5ff5\u3002\u6d4b\u8bd5\u4eba\u5458\u4f1a\u5141\u8bb8\u4e00\u5b9a\u7684\u8bef\u5dee\uff0c\u8bef\u5dee\u53ef\u80fd\u662f\u6b63\u5411\u7684\uff0c\u4e5f\u53ef\u80fd\u662f\u8d1f\u5411\u7684\u3002\u4e14\u8bef\u5dee\u7684\u5206\u5e03\u901a\u5e38\u4e5f\u9075\u5faa\u6b63\u6001\u5206\u5e03\uff0c\u5373\u5927\u90e8\u5206\u7684\u8bef\u5dee\u63a5\u8fd1\u4e8e0\uff0c\u5c0f\u90e8\u5206\u7684\u8bef\u5dee\u8f83\u4e3a\u6781\u7aef\u3002 \u4e0a\u8ff0\u63d0\u5230\u7684\u6982\u5ff5\u53ea\u4ec5\u9650\u4e8e\u4e00\u4e2a\u72ec\u7acb\u53d8\u91cf\u3002\u4f46\u5982\u679c\u6709\u4e24\u4e2a\u3001\u4e09\u4e2a\u72ec\u7acb\u53d8\u91cf\u5462\uff1f\u4ee5\u4e24\u4e2a\u72ec\u7acb\u53d8\u91cf\u4e3a\u4f8b\uff0c\u5176\u516c\u5f0f\u4f1a\u53d8\u4e3a y = b0 + b1x1 + b2x2\u3002\u5176\u793a\u4f8b\u56fe\u4e5f\u4f1a\u53d8\u4e3a\u4e09\u7ef4\u7684\uff0c\u5982\u4e0b\u56fe\u3002","title":"\u7ebf\u6027\u56de\u5f52 Linear Regression"},{"location":"dataAnalysis/dataAnalysis04/#python","text":"\u4e00\u4e2a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52 # \u5bfc\u5165\u6a21\u5757 from sklearn.linear_model import LinearRegression # \u521b\u5efa\u7ebf\u6027\u56de\u5f52\u5bf9\u8c61 lm = LinearRegression () # \u786e\u5b9a x \u548c y \u7684\u503c X = df [[ 'highway-mpg' ]] Y = df [[ 'price' ]] # \u4f7f\u7528 lm.fit \u8bad\u7ec3\u6a21\u578b lm . fit ( X , Y ) # \u786e\u5b9a b0, b1 \u7684\u503c b0 , b1 = lm . intercept_ , lm . coef_ # \u521b\u5efa yhat \u7ed3\u679c\u96c6 len(x)=len(yhat) Yhat = lm . predict ( X ) # \u5e94\u7528\u6d4b\u8bd5 \u4f1a\u8fd4\u56de x [0:5] \u5bf9\u5e94\u7684 y \u503c Yhat [ 0 : 5 ] \u591a\u4e2a\u53d8\u91cf\u7684\u7ebf\u6027\u56de\u5f52 # \u5c06\u591a\u4e2a\u53d8\u91cf\u50a8\u5b58\u5728\u5bf9\u8c61 Z \u4e2d Z = df [[ 'horsepower' , 'curb-weight' , 'engine-size' , 'highway-mpg' ]] lm . fit ( Z , df [ 'price' ]) # \u6d4b\u7b97 yhat Yhat = lm . predict ( Z ) # \u786e\u5b9ab0, b1, b2..\u7684\u503c b0 , b = lm . intercept_ , lm . coef_ # \u5176\u4e2d lm.coef_ \u7684\u5f62\u5f0f\u4e3aarray, \u5982 array([52.65, 4.70, 81.96, 33.58]) \u5176\u4e2d\uff0cY hat\u7684\u5b9a\u4e49\u4e3a: the predicted value of y (the dependent variable) in a regression equation . It can also be considered to be the average value of the response variable. The regression equation is just the equation which models the data set. \u5373\u6a21\u578b\u5728\u4e0d\u540c\u72ec\u7acb\u53d8\u91cf\u60c5\u51b5\u4e0b\u5e94\u7528\u6a21\u578b\u7684\u6d4b\u7b97\u503c\u3002","title":"\u5728 python \u4e2d\u5e94\u7528\u7ebf\u6027\u56de\u5f52"},{"location":"dataAnalysis/dataAnalysis04/#polynomial-regression","text":"\u591a\u5143\u56de\u5f52\u4e3a\u7ebf\u6027\u56de\u5f52\u7684\u4e00\u79cd\u7279\u6b8a\u8303\u7574\uff0c\u5176\u5728\u89e3\u91ca curvilinear relationship \u65f6\u975e\u5e38\u6709\u6548\u3002 curvilinear relationship \u6307\u91c7\u7528\u67d0\u4e2a\u53d8\u91cf\u7684\u5e73\u65b9\u503c\u6216 power \u6765\u4f5c\u4e3a x-value\u3002\u591a\u5143\u56de\u5f52\u548c multiple linear regression \u7684\u4e0d\u540c\u5728\u4e8e\u524d\u8005\u662f\u6709\u4e86\u5e73\u65b9\u3001\u7acb\u65b9\u7b49\uff0c\u800c\u540e\u8005\u4ec5\u662f\u6709\u4e86\u591a\u4e2a\u72ec\u7acb\u53d8\u91cf\u3002 * quadratic - squared degree 2 * cubic - 3rd order degree 3 * higher order \u53e6\u5916\u4e00\u79cd\u65b9\u5f0f\u662f\u4f7f\u7528 Pipelines\u3002Pipeline \u53ef\u4ee5\u6709\u6548\u7b80\u5316\u6a21\u578b\u5efa\u6a21\u7684\u6b65\u9aa4\u3002\u5982\u4e0b\u56fe\uff0c\u5305\u62ec\u4e86 3 \u4e2a\u6b65\u9aa4\uff0c\u6570\u636e\u6b63\u5e38\u5316\u3001\u591a\u9879\u5f0f\u56de\u5f52\u8f6c\u6362\u3001\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u6700\u540e\u8fd4\u56de yhat\u3002","title":"\u591a\u9879\u5f0f\u56de\u5f52 Polynomial Regression"},{"location":"dataAnalysis/dataAnalysis04/#python_1","text":"f = np . polyfit ( x , y , 3 ) # \u4f7f\u7528 poly1d \u8f6c\u6362\u4e3a\u516c\u5f0f p = np . poly1d ( f ) print ( p ) print ( np . ployfit ( x , y , 3 )) # array([-1.55663829e+00, 2.04754306e+02, -8.96543312e+03, 1.37923594e+05]) # \u4f7f\u7528 preprocessing \u5e93 from sklearn.preprocessing import PolynomialFeatures # \u521b\u5efa\u4e00\u4e2a degree/order =2 \u7684\u591a\u5143\u56de\u5f52\u5bf9\u8c61 pr = PolynomialFeatures ( degree = 2 , include_bias = False ) Z_pr = pr . fit_transform ( df [[ 'horsepower' , 'curb-weight' ]]) # \u67e5\u770b\u5404\u79cd\u7ec4\u5408\uff0c\u7b2c\u4e00\u4e2a\u6570\u636e\u4e3a\u6837\u672c\u503c\uff0c\u7b2c\u4e8c\u4e2a\u4e3a feature \u503c Z_pr . shape # (201,4) ::\u4f7f\u7528 pipelines:: from sklearn.preprocessing import PolynomialFeatures from sklearn.linear_model import LinearRegression from sklearn.preprocessing import StandardScaler # \u786e\u5b9a pipelien \u6b65\u9aa4 Input = [( 'scale' , StandardScaler ()), ( 'polynomial' , PolynomialFeatures ( degree = 2 )),( 'model' , LinearRegression ())] # \u521b\u5efa pipeline pipe = Pipeline ( Input ) Z = df [[ 'horsepower' , 'curb-weight' , 'engine-size' , 'highway-mpg' ]] . astype ( float ) y = df [ 'price' ] pipe . fit ( Z , y ) ypipe = pipe . predict ( Z ) ypipe [ 0 : 4 ]","title":"\u5728 python \u4e2d\u5b9e\u73b0\u591a\u9879\u5f0f\u56de\u5f52"},{"location":"dataAnalysis/dataAnalysis04/#_1","text":"","title":"\u6a21\u578b\u6d4b\u8bd5\u548c\u8bc4\u4f30"},{"location":"dataAnalysis/dataAnalysis04/#model-evaluation-using-visualization","text":"\u53ef\u4ee5\u4f7f\u7528 ::regression plot:: \u6765\u4ee5\u53ef\u89c6\u5316\u5730\u65b9\u5f0f\u76f4\u89c2\u7684\u8bc4\u4f30 Linear regression \uff0cregression plot \u53ef\u4ee5\u5c55\u793a\u4e24\u4e2a\u53d8\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\uff0c\u548c\u5173\u8054\u7cfb\u6570\u7684\u5f3a\u5ea6\uff0c\u4ee5\u53ca\u5173\u8054\u7684\u65b9\u5411\uff08\u6b63\u5173\u8054\u3001\u8d1f\u5173\u8054\uff09\u3002 Regression plot \u662f\u6563\u70b9\u56fe\u548c\u76f4\u7ebf\u56fe\u7684\u7ed3\u5408\u3002\u6bcf\u4e2a\u70b9\u4e3a\u5355\u4e2a\u6570\u636e\uff0c\u76f4\u7ebf\u56fe\u662f\u6700\u540e\u751f\u6210\u7684\u7ebf\u6027\u56de\u5f52\u7ebf\u3002 ::Residual plot:: \u7684 y \u662f \u5b9e\u9645\u503c-\u7ebf\u6027\u56de\u5f52\u9884\u6d4b\u503c y-yhat \uff0cx \u662f\u5f53\u65f6\u4f7f\u7528\u7684 x\uff0c\u4e5f\u53ef\u4ee5\u628a\u5176\u8ba4\u4e3a\u662f\u4e00\u7ec4\u7ec4\u7684\u8bef\u5dee\u3002\u6839\u636e\u6837\u672c x \u7684\u4e0d\u65ad\u589e\u591a\uff0c\u4f1a\u7ed8\u5236\u51fa\u4e00\u526f\u8bef\u5dee/\u566a\u97f3\u7684\u56fe\u3002\u5982\u679c\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u8db3\u591f\u51c6\u786e\uff0c\u8bef\u5dee\u5e94\u8be5\u662f y=0 \u7684\u4e00\u6761\u76f4\u7ebf\u3002 \u5982\u679c\u56fe\u793a\u7684\u70b9\u662f\u968f\u673a\u5206\u5e03\uff0c\u4ee3\u8868\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u5177\u6709\u4e00\u5b9a\u51c6\u786e\u6027\u3002 \u7136\u800c\u5982\u679c\u56fe\u793a\u7684\u70b9\u663e\u793a\u51fa\u4e86\u4e00\u5b9a\u7684\u89c4\u5f8b\uff0c\u4ee3\u8868\u6a21\u578b\u4e0d\u591f\u51c6\u786e\u3002 ::distribution plots:: \u4f1a\u4ee5\u67f1\u5f62\u56fe\u7684\u65b9\u5f0f\u540c\u65f6\u5448\u73b0\u9884\u6d4b\u503c (y hat) \u548c\u5b9e\u9645\u503c (y) \u5728\u4e0d\u540c\u533a\u95f4\u7684\u5206\u5e03\u3002 \u4e0a\u8ff0\u4e3a\u7b80\u7ea6\u7248\u672c\u7684 distribution plot \u4e0a\u8ff0\u4e3a\u4e00\u4e2a\u6837\u672c\u8db3\u591f\u591a\u7684\u5b9e\u9645\u7248\u672c\u7684 distribution plot \u4e0a\u8ff0\u4e3a\u91c7\u7528\u5355\u5143\u548c\u591a\u5143\u7ebf\u6027\u56de\u5f52\u7684\u5dee\u5f02\u5bf9\u6bd4\uff0c\u53ef\u4ee5\u6e05\u695a\u5730\u770b\u5230\u591a\u5143\u7ebf\u6027\u56de\u5f52\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c\u66f4\u52a0 fit \u5373\u66f4\u4e3a\u51c6\u786e\u3002","title":"\u6a21\u578b\u53ef\u89c6\u5316\u8bc4\u4f30 Model Evaluation Using Visualization"},{"location":"dataAnalysis/dataAnalysis04/#python_2","text":"import seaborn as sns # regression plot sns . regplot ( x = \"highway-mpg\" , y = \"price\" , data = df ) plt . ylim ( 0 ,) # residual plot sns . residplot ( df [ 'highway-mpg' ], df [ 'price' ]) # distribution plot # \u7ed8\u5236\u771f\u5b9e\u7684\u503c\u5206\u5e03 ax1 = sns . distplot ( df [ 'price' ], hist = False , color = 'r' , label = 'actual value' ) # \u7ed8\u5236\u6839\u636e\u6a21\u578b\u9884\u6d4b\u7684\u503c\u5206\u5e03\uff0c\u57fa\u51c6\u7ebf\u4e3a ax 1 sns . displot ( Y_hat , hist = False , color = 'b' , label = 'fitted values' , ax = ax1 )","title":"\u5728 python \u4e2d\u53ef\u89c6\u5316\u6a21\u578b\u7ed3\u679c"},{"location":"dataAnalysis/dataAnalysis04/#in-sample-evaluation","text":"\u6837\u672c\u6d4b\u8bd5\u53ef\u4ee5\u91cf\u5316\u8bc4\u4f30\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9002\u914d\u6027\u3002\u4e24\u79cd\u5e38\u7528\u7684\u6d4b\u8bd5\u65b9\u6cd5\u4e3a\uff1a 1. Mean Squared Error (MSE) \u5373\u8bef\u5dee\u7684\u5e73\u65b9\u603b\u548c / \u6837\u672c\u6570 2. R-squared (R^2) / coefficient of Determination \u76ee\u6807\u53d8\u91cf\u53ef\u4ee5\u7528\u6a21\u578b\u6765\u89e3\u91ca\u7684\u767e\u5206\u6bd4 R^2 = ( 1 - MSE of regression line / MSE of the average of the data) \u901a\u5e38\u6765\u8bf4\u8303\u7574\u4e3a [0,1] \u84dd\u7ebf\u4e3a\u7ebf\u6027\u56de\u5f52\u6a21\u578b\uff0c\u7ea2\u7ebf\u4e3a\u6307\u5b9a\u53d8\u91cf\u7684\u5e73\u5747\u503c\u3002 \u84dd\u8272\u65b9\u5757\u4e3a\u6a21\u578b\u7684MSE\uff0c\u7ea2\u7ebf\u4e3a\u5e73\u5747\u503c\u7684MSE\u3002 \u7531\u4e0a\u56fe\u53ef\u53d1\u73b0\u84dd\u8272\u65b9\u5757\u663e\u8457\u5c0f\u4e8e\u7ea2\u8272\u65b9\u5757\uff0c\u8bc1\u5b9e\u4e86\u6a21\u578b\u7684\u6709\u6548\u6027\u3002\u5728\u6b64\u60c5\u51b5\u4e0b\uff0cMSE of regression line / MSE of y hat (\u84dd\u8272\u65b9\u5757/\u7ea2\u8272\u65b9\u5757) \u4f1a\u63a5\u8fd1\u4e8e0\u3002 # MSE from sklearn.metrics import mean_squared_error # \u7b2c\u4e00\u4e2a\u503c\u4e3a\u771f\u5b9e\u503c\uff0c\u7b2c\u4e8c\u4e2a\u503c\u4e3a\u6a21\u578b\u6d4b\u7b97\u51fa\u7684\u503c Yhat = lm . predict ( X ) mse = mean_squared_error ( df [ 'price' ], Yhat ) # R-squared X = df [[ 'highway-mpg' ]] Y = df [ 'price' ] lm . fit ( X , Y ) lm . score ( X , Y ) # R2_score from sklearn.metrics import r2_score r_squared = r2_score ( y , p ( x ))","title":"\u6a21\u578b\u6837\u672c\u6d4b\u8bd5 In-Sample Evaluation"},{"location":"dataAnalysis/dataAnalysis04/#_2","text":"\u6709\u4e0b\u5217\u51e0\u79cd\u65b9\u5f0f\u53ef\u4ee5\u8bc4\u4f30\u6a21\u578b\uff1a 1. \u6d4b\u7b97\u7684\u7ed3\u679c\u662f\u5426\u6709\u4f9d\u53ef\u5faa 2. \u53ef\u89c6\u5316\u7ed3\u679c\u5c55\u793a: residual plot, distribution plot 3. \u91cf\u5316\u8bc4\u4f30\u5206\u6790: MSE \u6216 R-squared\uff0c\u5176\u4e2d\u901a\u5e38\u6765\u8bf4 MSE \u8d8a\u5c0f\u8d8a\u597d\uff0cr-squared \u8d8a\u5927\u8d8a\u597d 4. \u6a21\u578b\u95f4\u6bd4\u8f83\u8bc4\u4f30: SLR vs. MLR, MLR vs PLR import numpy as np # arrange(x,y,z) x\u4e3a\u8d77\u59cb\u70b9 y\u4e3a\u7ec8\u7ed3\u70b9\uff0cz\u4e3a\u6b65\u6570 new_input = np . arrange ( 1 , 101 , 1 ) . reshape ( - 1 , 1 ) # \u4f7f\u7528\u6a21\u578b yhat = lm . predict ( new_input ) \u6570\u503c\u8f83\u5c0f\u7684 MSE \u662f\u5426\u4ee3\u8868\u6a21\u578b\u66f4\u9ad8\u7684\u9002\u914d\u6027\uff1f \u7b54\u6848\u5e76\u4e0d\u7edd\u5bf9\u3002\u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u7684MSE\u901a\u5e38\u4f1a\u5c0f\u4e8e\u7b80\u5355\u7ebf\u6027\u56de\u5f52\uff08MSE for a multiple linear regression model will be smaller than the MSE for a simple linear regression model\uff09\u3002\u56e0\u4e3a\u591a\u7ef4\u7ebf\u6027\u56de\u5f52\u7eb3\u5165\u4e86\u66f4\u591a\u7684\u6307\u5b9a\u53d8\u91cf\u3002 X variable / independent variable / explanatory variable / predictor variable Y variable / dependent variable / response variable","title":"\u8bc4\u4f30\u548c\u51b3\u7b56\u5236\u5b9a"},{"location":"dataAnalysis/dataAnalysis05/","text":"Python05 \u6a21\u578b\u8bc4\u4f30\u548c\u4f18\u5316 \u672c\u7ae0\u8282\u4f1a\u6d89\u53ca\u5230\uff1a 1. In-sample data (training data) vs. out-of-sample data (test set) 2. Over-fitting, Under-fitting and Model Selection \u8fc7\u62df\u5408, \u6b20\u62df\u5408\u548c\u6a21\u578b\u9009\u62e9 3. Ridge Regression \u5cad\u56de\u5f52 \u6570\u636e\u5206\u7ec4\u548c\u4ea4\u53c9\u68c0\u9a8c \u53ef\u884c\u7684\u65b9\u6cd5\u662f\u5c06\u6570\u636e\u5206\u4e3a\u8bad\u7ec3\u7ec4\u548c\u6d4b\u8bd5\u7ec4\u3002\u8bad\u7ec3\u7ec4\u4e00\u822c\u4e3a 70% \u7684\u6570\u636e\uff0c\u800c\u6d4b\u8bd5\u7ec4\u4e00\u822c\u4e3a 30% \u7684\u6570\u636e\u3002 \u4f7f\u7528\u8bad\u7ec3\u7ec4\u6765\u57f9\u8bad\u6a21\u578b\uff0c\u6d4b\u8bd5\u7ec4\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9002\u914d\u6027\u8868\u73b0 \u3002\u5f53\u786e\u5b9a\u6700\u7ec8\u4f7f\u7528\u7684\u6a21\u578b\u540e\uff0c\u5e94\u4f7f\u7528\u5168\u90e8\u7684\u6570\u636e\u6765\u57f9\u8bad\u6a21\u578b\u3002 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 train_test_split() \u6765\u5c06\u6570\u636e\u968f\u673a\u5206\u4e3a\u8bad\u7ec3\u7ec4\u548c\u6d4b\u8bd5\u7ec4\u3002 from sklearn.model_select import train_test_split # \u6570\u636e\u5206\u7ec4 # random_state is the number generator used for random sampling x_train , x_test , y_train , y_test = train_test_split ( x_data , y_data , test_size = 0.3 , random_state = 0 ) \u4e0a\u56fe\u5de6\u4fa7\u662f \u8bad\u7ec3\u7ec4 \u5b9e\u9645\u548c\u4f30\u6d4b\u503c\u7684\u5bf9\u6bd4\uff0c\u53f3\u4fa7\u662f \u6d4b\u8bd5\u7ec4 \u5b9e\u9645\u548c\u4f30\u6d4b\u503c\u7684\u5bf9\u6bd4\u3002\u4e24\u8005\u4e4b\u95f4\u6709\u8f83\u5927\u7684\u4e00\u4e2a\u5dee\u8ddd\uff0c\u7edf\u8ba1\u5b66\u4e2d\u5c06\u5176\u5f52\u7eb3\u4e3a\u6cdb\u5316\u8bef\u5dee / Generalization Error\u3002\u5373 * \u8bad\u7ec3\u7ec4\u7684\u6570\u636e\u6837\u672c\u8d8a\u5927\uff0c\u5219\u6bcf\u6b21\u6a21\u578b\u5f97\u51fa\u7684\u7ed3\u679c\u5dee\u5f02\u4f1a\u66f4\u5927\uff0c\u4f46\u6a21\u578b\u7ed3\u679c\u4f1a\u66f4\u63a5\u8fd1\u771f\u5b9e\u7ed3\u679c * \u8bad\u7ec3\u7ec4\u7684\u6570\u636e\u6837\u672c\u8d8a\u5c0f\uff0c\u5219\u6bcf\u6b21\u6a21\u578b\u5f97\u51fa\u7684\u7ed3\u679c\u5dee\u5f02\u4f1a\u66f4\u5c0f\uff0c\u4f46\u6a21\u578b\u7ed3\u679c\u4f1a\u66f4\u8fdc\u79bb\u771f\u5b9e\u7ed3\u679c \u53ef\u4ee5\u4f7f\u7528 ::\u4ea4\u53c9\u6821\u9a8c / Cross Validation:: \u6765\u89e3\u51b3\u6cdb\u5316\u8bef\u5dee\u3002\u4ea4\u53c9\u6821\u9a8c\u7684\u6982\u5ff5\u53ef\u4ee5\u4ee5\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u6765\u8bf4\u660e\u3002\u5047\u8bbe\u6570\u636e\u88ab\u5206\u4e3a\u4e86 4 \u7ec4\u3002\u6bcf\u6b21\u7528 3 \u7ec4\u8bad\u7ec3\uff0c1 \u7ec4\u6d4b\u8bd5\u3002\u603b\u5171\u8bad\u7ec3\u6a21\u578b 4 \u6b21\uff0c\u6bcf\u7ec4\u90fd\u4f1a\u6210\u4e3a 3 \u6b21\u8bad\u7ec3\u7ec4\uff0c 1 \u6b21\u6d4b\u8bd5\u7ec4\uff0c\u6700\u540e\u4f1a\u751f\u6210 4 \u4e2a r-squared \u503c\u3002 \u6d4b\u8bd5\u4ea4\u53c9\u68c0\u9a8c\u6a21\u578b\u7684 R-square \u53ef\u4ee5\u4f7f\u7528 cross_val_score() \u65b9\u6cd5\u3002 from sklearn.model_selection import cross_val_score , cross_val_predict # cv \u6307\u4ee3\u5c06\u6570\u636e\u5206\u4e3a\u51e0\u7ec4\uff08folds\uff09\u4f1a\u8fd4\u56de R-squared \u7684\u5e73\u5747\u503c scores = cross_val_score ( lr , x_data , y_data , cv = 3 ) np . mean ( scores ) # \u4ea4\u53c9\u68c0\u9a8c\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c \u4f1a\u8fd4\u56de\u9884\u6d4b\u503c\u7684\u5e73\u5747\u503c Yhat = cross_val_predict ( lr , x_data , y_data , cv = 3 ) \u8fc7\u62df\u5408\u3001\u6b20\u62df\u5408\u548c\u6a21\u578b\u9009\u62e9 \u53f3\u4fa7\u56fe\u793a\u4e3a \u6b20\u62df\u5408\uff08under-fitting) \u5373\u6a21\u578b\u8fc7\u4e8e\u7b80\u5355\u5bfc\u81f4\u6a21\u578b\u7ed3\u679c\u548c\u771f\u5b9e\u6570\u636e\u5dee\u8ddd\u5f88\u5927 \u5de6\u4fa7\u56fe\u793a\u4e3a \u8fc7\u62df\u5408\uff08over-fitting) \u3002\u6b64\u65f6\u6a21\u578b order = 16\u3002\u8fc7\u62df\u5408\u6307\u4ee3\u6a21\u578b\u8fc7\u4e8e\u590d\u6742\uff0c\u5bfc\u81f4\u90e8\u5206\u533a\u95f4\u56e0\u4e3a\u8bad\u7ec3\u6837\u672c\u8fc7\u5c11\u800c\u6a21\u578b\u4e3a\u4e86\u8d34\u8fd1\u8bad\u7ec3\u6570\u636e\uff0c\u6a21\u578b\u7ed3\u679c\u51fa\u73b0\u8f83\u5927\u7684\u504f\u5dee \u53ef\u4ee5\u770b\u51fa\uff0c\u968f\u7740 order \u589e\u591a\uff0c\u6a21\u578b\u8d8a\u590d\u6742\u4e14\u6a21\u578b\u5728\u8bad\u7ec3\u6837\u672c\u4e0a\u5f97\u51fa\u7684\u7ed3\u679c\u8d8a\u51c6\u786e\uff0c\u4f46\u968f\u4e4b\u800c\u6765\u7684\u8fd8\u6709\u964d\u4f4e\u7684\u6d4b\u8bd5\u6837\u672c\u7ed3\u679c\u51c6\u786e\u6027\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u9009\u62e9\u6d4b\u8bd5\u6837\u672c\u8bef\u5dee\u6700\u5c0f\u7684\u6a21\u578b\uff0c \u5728\u4e0a\u56fe\u793a\u4f8b\u4e2d\u4e3a order = 8\u3002\u5982\u679c order < 8\uff0c\u6a21\u578b\u6b20\u62df\u5408\u3002\u5982\u679c order > 8\uff0c\u5219\u6a21\u578b\u8fc7\u62df\u5408\u3002 \u7136\u800c\u5373\u4f7f\u6211\u4eec\u9009\u62e9\u4e86 order = 8 \u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u770b\u5230 MSE \u4f9d\u65e7\u5b58\u5728\u3002\u5176\u6839\u672c\u539f\u56e0\u662f\u56e0\u4e3a\u6570\u636e\u5b58\u5728 noise\u3002noise \u4e5f\u88ab\u79f0\u4e3a irreducible error\uff0c\u5373\u65e0\u6cd5\u6d88\u9664\u7684\u8bef\u5dee\u3002 \u5728\u9009\u62e9\u4f7f\u7528\u4f55\u79cd\u6a21\u578b\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u8003\u8651\u4f7f\u7528 order vs. R-squared\u3002\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\u5f53 order = 3 \u7684\u65f6\u5019 r-squared \u503c\u6700\u9ad8\uff0c\u5373\u6a21\u578b\u89e3\u91ca\u4e86\u6700\u9ad8\u5360\u6bd4\u7684\u6d4b\u8bd5\u6570\u636e\u3002\u800c\u5f53 order > 3\u7684\u65f6\u5019\uff0cr-squared \u8fc5\u901f\u4e0b\u964d\u3002 Rsqu_test = [] order = [ 1 , 2 , 3 , 4 ] for n in order : pr = PolynomialFeatures ( degree = n ) x_train_pr = pr . fit_transform ( x_tain [[ 'horsepower' ]]) x_test_pr = pr . fit_transform ( x_test [[ 'horsepower' ]]) lr . fit ( x_train_pr , y_train ) # \u8ba1\u7b97 r-squared Rsqu_test . append ( lr . score ( x_test_pr , y_test )) \u5cad\u56de\u5f52 Ridge Regression Ridge regression is a regression that is employed in a Multiple regression model when Multicollinearity occurs. Multicollinearity is when there is a strong relationship among the independent variables. Ridge regression is very common with polynomial regression. The next video shows how Ridge regression is used to regularize and reduce the standard errors to avoid over-fitting a regression model \u5f53\u591a\u5143\u7ebf\u6027\u56de\u5f52\u4e2d\u7684 x-variable \u5373 \u72ec\u7acb\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u5173\u7cfb\u7684\u65f6\u5019\uff08\u5373\u591a\u91cd\u5171\u7ebf\u6027\uff09 \uff0c\u5cad\u56de\u5f52\u53ef\u4ee5\u6709\u6548\u7684\u89e3\u51b3\u6a21\u578b\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u5cad\u56de\u5f52\u3002 \u73b0\u5728\u5047\u8bbe\u4e00\u4e2a\u60c5\u666f\uff0c\u6a21\u578b\u5df2\u7ecf\u88ab\u8bad\u7ec3\u7684\u7b26\u5408 99% \u7684\u8bad\u7ec3\u6570\u636e\u4e86\u3002\u4f46\u662f\u6709 1% \u7684\u6570\u636e\u662f outlier\u3002\u4e3a\u4e86\u5951\u51c6\u8fd9\u4e9b outlier \u6570\u636e\uff0c\u6a21\u578b\u7684 order \u4f1a\u4e0a\u523010\uff0c\u5982 Yhat = 1 + 2x - 3x^2 - 2x^3 - 12x^4 - 40x^5 + 80x^6 + 71x^7 - 141x^8 - 38x^9 + 75x^10\u3002 \u53ef\u4ee5\u770b\u5230\u4e0a\u8ff0\u6a21\u578b\u7684 coef \u6d6e\u52a8\u975e\u5e38\u5927\u3002\u6700\u5c0f\u4e3a1\uff0c\u6700\u5927\u4e3a 141\uff0c\u8fd9\u4e5f\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u90e8\u5206 x-varible \u533a\u95f4\u4f1a\u5931\u7075\u3002\u5728\u6b64\u65f6\u53ef\u4ee5 \u5f15\u5165 Alpha \u6765\u89e3\u51b3\u7cfb\u6570\u6d6e\u52a8\u8fc7\u5927\u7684\u95ee\u9898 \u3002 Alpha \u7684\u9009\u62e9\u9700\u8981\u8c28\u614e\u3002 \u968f\u7740 Alpha \u7684\u9010\u6e10\u589e\u5927\uff0c\u7cfb\u6570\u548c\u7cfb\u6570\u7684\u6d6e\u52a8\u533a\u57df\u4f1a\u9010\u6e10\u53d8\u5c0f\u3002\u4f46\u8fd9\u4e5f\u4f1a\u5bfc\u81f4\u6a21\u578b under fitting \u968f\u7740 Alpha \u7684\u9010\u6e10\u53d8\u5c0f\uff0c\u7cfb\u6570\u548c\u7cfb\u6570\u7684\u6d6e\u52a8\u533a\u57df\u4f1a\u9010\u6e10\u53d8\u5927\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u6a21\u578b\u7684 over-fitting \u5728\u51b3\u5b9a Alpha \u7cfb\u6570\u7684\u9009\u62e9\u4e0a\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ea4\u53c9\u68c0\u9a8c\u3002\u5c06\u6570\u636e\u5206\u7ec4\uff0c\u4e00\u7ec4\u5206\u4e3a\u8bad\u7ec3\u7ec4\uff0c\u53e6\u4e00\u7ec4\u5206\u4e3a predict \u7ec4\uff0c\u4e4b\u540e\u5c1d\u8bd5\u4e0d\u540c\u7684 alpha \u503c\uff0c\u7136\u540e\u5f97\u51fa\u4e00\u5f20 alpha -> R-squared \u7684\u5bf9\u5e94\u8868\u5355\u503c\uff0c\u6700\u540e\u51b3\u5b9a\u5e94\u8be5\u4f7f\u7528\u54ea\u4e2a alpha \u503c\u3002 from sklearn.linear_model import Ridge RidgeModel = Ridge ( alpha = 0.1 ) RidgeModel . fit ( X , y ) # R-squared RidgeModel . score ( X , y ) Yhat = RidgeModel . predict ( X ) \u7f51\u683c\u641c\u7d22 Grid Search \u5cad\u56de\u5f52\u4e2d\u7684 alpha \u88ab\u79f0\u4e3a hyperparameter \u8d85\u53c2\u6570\u3002Scikit-learn \u4e2d\u53ef\u4ee5\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u5b9e\u73b0\u81ea\u52a8\u5316\u5c1d\u8bd5\u5404\u79cd alpha \u53c2\u6570\u7ec4\u5408\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u6821\u9a8c\u6765\u6838\u7b97 MSE \u4ee5\u9a8c\u8bc1\u6bcf\u79cd\u7ec4\u5408\u7684\u51c6\u786e\u6027\uff0c\u6700\u540e\u8fd4\u56de\u6700\u4f73\u7684 alpha \u7cfb\u6570\u3002 \u6570\u636e\u4f1a\u5206\u4e3a 3 \u7ec4\uff1aTraining Set, Validation Set, Test Set. \u4f7f\u7528\u4e0d\u540c\u7684 hyperparameter \u548c\u8bad\u7ec3\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4e4b\u540e\u4f7f\u7528\u9a8c\u8bc1\u6570\u636e\u6765\u5f97\u51fa MSE \u6216 R-squared \u7684\u503c\uff0c\u9009\u62e9 MSE \u6700\u5c0f\u6216 R-squared \u6700\u5927\u60c5\u666f\u4e0b\u7684 hyperparameter \u503c\u3002\u6700\u540e\u4f7f\u7528\u5b9e\u9a8c\u7ec4\u6570\u636e\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002 from sklearn.linear_model import Ridge from sklearn.model_selection import GridSearchCV parameters1 = [{ 'alpha' :[ 1 , 10 , 100 , 1000 , 10000 , 100000 ], 'normalize' :[ True , False ]}] RR = Ridge () Grid1 = GridSearchCV ( RR , parameters1 , cv = 4 ) Grid1 . fit ( x_data [[ 'horsepower' , 'curb-weight' , 'highway-mpg' ]], y_data ) Grid1 . best_estimator_ scores = Grid1 . cv_results_ scores [ 'mean_test_score' ]","title":"\u6a21\u578b\u68c0\u9a8c\u548c\u4f18\u5316"},{"location":"dataAnalysis/dataAnalysis05/#python05","text":"\u672c\u7ae0\u8282\u4f1a\u6d89\u53ca\u5230\uff1a 1. In-sample data (training data) vs. out-of-sample data (test set) 2. Over-fitting, Under-fitting and Model Selection \u8fc7\u62df\u5408, \u6b20\u62df\u5408\u548c\u6a21\u578b\u9009\u62e9 3. Ridge Regression \u5cad\u56de\u5f52","title":"Python05 \u6a21\u578b\u8bc4\u4f30\u548c\u4f18\u5316"},{"location":"dataAnalysis/dataAnalysis05/#_1","text":"\u53ef\u884c\u7684\u65b9\u6cd5\u662f\u5c06\u6570\u636e\u5206\u4e3a\u8bad\u7ec3\u7ec4\u548c\u6d4b\u8bd5\u7ec4\u3002\u8bad\u7ec3\u7ec4\u4e00\u822c\u4e3a 70% \u7684\u6570\u636e\uff0c\u800c\u6d4b\u8bd5\u7ec4\u4e00\u822c\u4e3a 30% \u7684\u6570\u636e\u3002 \u4f7f\u7528\u8bad\u7ec3\u7ec4\u6765\u57f9\u8bad\u6a21\u578b\uff0c\u6d4b\u8bd5\u7ec4\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u51c6\u786e\u6027\u548c\u9002\u914d\u6027\u8868\u73b0 \u3002\u5f53\u786e\u5b9a\u6700\u7ec8\u4f7f\u7528\u7684\u6a21\u578b\u540e\uff0c\u5e94\u4f7f\u7528\u5168\u90e8\u7684\u6570\u636e\u6765\u57f9\u8bad\u6a21\u578b\u3002 \u5728 python \u4e2d\u53ef\u4ee5\u4f7f\u7528 train_test_split() \u6765\u5c06\u6570\u636e\u968f\u673a\u5206\u4e3a\u8bad\u7ec3\u7ec4\u548c\u6d4b\u8bd5\u7ec4\u3002 from sklearn.model_select import train_test_split # \u6570\u636e\u5206\u7ec4 # random_state is the number generator used for random sampling x_train , x_test , y_train , y_test = train_test_split ( x_data , y_data , test_size = 0.3 , random_state = 0 ) \u4e0a\u56fe\u5de6\u4fa7\u662f \u8bad\u7ec3\u7ec4 \u5b9e\u9645\u548c\u4f30\u6d4b\u503c\u7684\u5bf9\u6bd4\uff0c\u53f3\u4fa7\u662f \u6d4b\u8bd5\u7ec4 \u5b9e\u9645\u548c\u4f30\u6d4b\u503c\u7684\u5bf9\u6bd4\u3002\u4e24\u8005\u4e4b\u95f4\u6709\u8f83\u5927\u7684\u4e00\u4e2a\u5dee\u8ddd\uff0c\u7edf\u8ba1\u5b66\u4e2d\u5c06\u5176\u5f52\u7eb3\u4e3a\u6cdb\u5316\u8bef\u5dee / Generalization Error\u3002\u5373 * \u8bad\u7ec3\u7ec4\u7684\u6570\u636e\u6837\u672c\u8d8a\u5927\uff0c\u5219\u6bcf\u6b21\u6a21\u578b\u5f97\u51fa\u7684\u7ed3\u679c\u5dee\u5f02\u4f1a\u66f4\u5927\uff0c\u4f46\u6a21\u578b\u7ed3\u679c\u4f1a\u66f4\u63a5\u8fd1\u771f\u5b9e\u7ed3\u679c * \u8bad\u7ec3\u7ec4\u7684\u6570\u636e\u6837\u672c\u8d8a\u5c0f\uff0c\u5219\u6bcf\u6b21\u6a21\u578b\u5f97\u51fa\u7684\u7ed3\u679c\u5dee\u5f02\u4f1a\u66f4\u5c0f\uff0c\u4f46\u6a21\u578b\u7ed3\u679c\u4f1a\u66f4\u8fdc\u79bb\u771f\u5b9e\u7ed3\u679c \u53ef\u4ee5\u4f7f\u7528 ::\u4ea4\u53c9\u6821\u9a8c / Cross Validation:: \u6765\u89e3\u51b3\u6cdb\u5316\u8bef\u5dee\u3002\u4ea4\u53c9\u6821\u9a8c\u7684\u6982\u5ff5\u53ef\u4ee5\u4ee5\u4e00\u4e2a\u7b80\u5355\u7684\u4f8b\u5b50\u6765\u8bf4\u660e\u3002\u5047\u8bbe\u6570\u636e\u88ab\u5206\u4e3a\u4e86 4 \u7ec4\u3002\u6bcf\u6b21\u7528 3 \u7ec4\u8bad\u7ec3\uff0c1 \u7ec4\u6d4b\u8bd5\u3002\u603b\u5171\u8bad\u7ec3\u6a21\u578b 4 \u6b21\uff0c\u6bcf\u7ec4\u90fd\u4f1a\u6210\u4e3a 3 \u6b21\u8bad\u7ec3\u7ec4\uff0c 1 \u6b21\u6d4b\u8bd5\u7ec4\uff0c\u6700\u540e\u4f1a\u751f\u6210 4 \u4e2a r-squared \u503c\u3002 \u6d4b\u8bd5\u4ea4\u53c9\u68c0\u9a8c\u6a21\u578b\u7684 R-square \u53ef\u4ee5\u4f7f\u7528 cross_val_score() \u65b9\u6cd5\u3002 from sklearn.model_selection import cross_val_score , cross_val_predict # cv \u6307\u4ee3\u5c06\u6570\u636e\u5206\u4e3a\u51e0\u7ec4\uff08folds\uff09\u4f1a\u8fd4\u56de R-squared \u7684\u5e73\u5747\u503c scores = cross_val_score ( lr , x_data , y_data , cv = 3 ) np . mean ( scores ) # \u4ea4\u53c9\u68c0\u9a8c\u6a21\u578b\u7684\u9884\u6d4b\u7ed3\u679c \u4f1a\u8fd4\u56de\u9884\u6d4b\u503c\u7684\u5e73\u5747\u503c Yhat = cross_val_predict ( lr , x_data , y_data , cv = 3 )","title":"\u6570\u636e\u5206\u7ec4\u548c\u4ea4\u53c9\u68c0\u9a8c"},{"location":"dataAnalysis/dataAnalysis05/#_2","text":"\u53f3\u4fa7\u56fe\u793a\u4e3a \u6b20\u62df\u5408\uff08under-fitting) \u5373\u6a21\u578b\u8fc7\u4e8e\u7b80\u5355\u5bfc\u81f4\u6a21\u578b\u7ed3\u679c\u548c\u771f\u5b9e\u6570\u636e\u5dee\u8ddd\u5f88\u5927 \u5de6\u4fa7\u56fe\u793a\u4e3a \u8fc7\u62df\u5408\uff08over-fitting) \u3002\u6b64\u65f6\u6a21\u578b order = 16\u3002\u8fc7\u62df\u5408\u6307\u4ee3\u6a21\u578b\u8fc7\u4e8e\u590d\u6742\uff0c\u5bfc\u81f4\u90e8\u5206\u533a\u95f4\u56e0\u4e3a\u8bad\u7ec3\u6837\u672c\u8fc7\u5c11\u800c\u6a21\u578b\u4e3a\u4e86\u8d34\u8fd1\u8bad\u7ec3\u6570\u636e\uff0c\u6a21\u578b\u7ed3\u679c\u51fa\u73b0\u8f83\u5927\u7684\u504f\u5dee \u53ef\u4ee5\u770b\u51fa\uff0c\u968f\u7740 order \u589e\u591a\uff0c\u6a21\u578b\u8d8a\u590d\u6742\u4e14\u6a21\u578b\u5728\u8bad\u7ec3\u6837\u672c\u4e0a\u5f97\u51fa\u7684\u7ed3\u679c\u8d8a\u51c6\u786e\uff0c\u4f46\u968f\u4e4b\u800c\u6765\u7684\u8fd8\u6709\u964d\u4f4e\u7684\u6d4b\u8bd5\u6837\u672c\u7ed3\u679c\u51c6\u786e\u6027\u3002 \u6211\u4eec\u7684\u76ee\u6807\u662f\u9009\u62e9\u6d4b\u8bd5\u6837\u672c\u8bef\u5dee\u6700\u5c0f\u7684\u6a21\u578b\uff0c \u5728\u4e0a\u56fe\u793a\u4f8b\u4e2d\u4e3a order = 8\u3002\u5982\u679c order < 8\uff0c\u6a21\u578b\u6b20\u62df\u5408\u3002\u5982\u679c order > 8\uff0c\u5219\u6a21\u578b\u8fc7\u62df\u5408\u3002 \u7136\u800c\u5373\u4f7f\u6211\u4eec\u9009\u62e9\u4e86 order = 8 \u7684\u6a21\u578b\uff0c\u53ef\u4ee5\u770b\u5230 MSE \u4f9d\u65e7\u5b58\u5728\u3002\u5176\u6839\u672c\u539f\u56e0\u662f\u56e0\u4e3a\u6570\u636e\u5b58\u5728 noise\u3002noise \u4e5f\u88ab\u79f0\u4e3a irreducible error\uff0c\u5373\u65e0\u6cd5\u6d88\u9664\u7684\u8bef\u5dee\u3002 \u5728\u9009\u62e9\u4f7f\u7528\u4f55\u79cd\u6a21\u578b\u7684\u65f6\u5019\uff0c\u53ef\u4ee5\u8003\u8651\u4f7f\u7528 order vs. R-squared\u3002\u4e0a\u56fe\u53ef\u4ee5\u770b\u5230\u5f53 order = 3 \u7684\u65f6\u5019 r-squared \u503c\u6700\u9ad8\uff0c\u5373\u6a21\u578b\u89e3\u91ca\u4e86\u6700\u9ad8\u5360\u6bd4\u7684\u6d4b\u8bd5\u6570\u636e\u3002\u800c\u5f53 order > 3\u7684\u65f6\u5019\uff0cr-squared \u8fc5\u901f\u4e0b\u964d\u3002 Rsqu_test = [] order = [ 1 , 2 , 3 , 4 ] for n in order : pr = PolynomialFeatures ( degree = n ) x_train_pr = pr . fit_transform ( x_tain [[ 'horsepower' ]]) x_test_pr = pr . fit_transform ( x_test [[ 'horsepower' ]]) lr . fit ( x_train_pr , y_train ) # \u8ba1\u7b97 r-squared Rsqu_test . append ( lr . score ( x_test_pr , y_test ))","title":"\u8fc7\u62df\u5408\u3001\u6b20\u62df\u5408\u548c\u6a21\u578b\u9009\u62e9"},{"location":"dataAnalysis/dataAnalysis05/#ridge-regression","text":"Ridge regression is a regression that is employed in a Multiple regression model when Multicollinearity occurs. Multicollinearity is when there is a strong relationship among the independent variables. Ridge regression is very common with polynomial regression. The next video shows how Ridge regression is used to regularize and reduce the standard errors to avoid over-fitting a regression model \u5f53\u591a\u5143\u7ebf\u6027\u56de\u5f52\u4e2d\u7684 x-variable \u5373 \u72ec\u7acb\u53d8\u91cf\u4e4b\u95f4\u5b58\u5728\u5173\u7cfb\u7684\u65f6\u5019\uff08\u5373\u591a\u91cd\u5171\u7ebf\u6027\uff09 \uff0c\u5cad\u56de\u5f52\u53ef\u4ee5\u6709\u6548\u7684\u89e3\u51b3\u6a21\u578b\u8fc7\u62df\u5408\u7684\u95ee\u9898\u3002\u591a\u9879\u5f0f\u56de\u5f52\u6a21\u578b\u4e2d\u7ecf\u5e38\u4f7f\u7528\u5cad\u56de\u5f52\u3002 \u73b0\u5728\u5047\u8bbe\u4e00\u4e2a\u60c5\u666f\uff0c\u6a21\u578b\u5df2\u7ecf\u88ab\u8bad\u7ec3\u7684\u7b26\u5408 99% \u7684\u8bad\u7ec3\u6570\u636e\u4e86\u3002\u4f46\u662f\u6709 1% \u7684\u6570\u636e\u662f outlier\u3002\u4e3a\u4e86\u5951\u51c6\u8fd9\u4e9b outlier \u6570\u636e\uff0c\u6a21\u578b\u7684 order \u4f1a\u4e0a\u523010\uff0c\u5982 Yhat = 1 + 2x - 3x^2 - 2x^3 - 12x^4 - 40x^5 + 80x^6 + 71x^7 - 141x^8 - 38x^9 + 75x^10\u3002 \u53ef\u4ee5\u770b\u5230\u4e0a\u8ff0\u6a21\u578b\u7684 coef \u6d6e\u52a8\u975e\u5e38\u5927\u3002\u6700\u5c0f\u4e3a1\uff0c\u6700\u5927\u4e3a 141\uff0c\u8fd9\u4e5f\u4f1a\u5bfc\u81f4\u6a21\u578b\u5728\u90e8\u5206 x-varible \u533a\u95f4\u4f1a\u5931\u7075\u3002\u5728\u6b64\u65f6\u53ef\u4ee5 \u5f15\u5165 Alpha \u6765\u89e3\u51b3\u7cfb\u6570\u6d6e\u52a8\u8fc7\u5927\u7684\u95ee\u9898 \u3002 Alpha \u7684\u9009\u62e9\u9700\u8981\u8c28\u614e\u3002 \u968f\u7740 Alpha \u7684\u9010\u6e10\u589e\u5927\uff0c\u7cfb\u6570\u548c\u7cfb\u6570\u7684\u6d6e\u52a8\u533a\u57df\u4f1a\u9010\u6e10\u53d8\u5c0f\u3002\u4f46\u8fd9\u4e5f\u4f1a\u5bfc\u81f4\u6a21\u578b under fitting \u968f\u7740 Alpha \u7684\u9010\u6e10\u53d8\u5c0f\uff0c\u7cfb\u6570\u548c\u7cfb\u6570\u7684\u6d6e\u52a8\u533a\u57df\u4f1a\u9010\u6e10\u53d8\u5927\uff0c\u4f46\u8fd9\u4f1a\u5bfc\u81f4\u6a21\u578b\u7684 over-fitting \u5728\u51b3\u5b9a Alpha \u7cfb\u6570\u7684\u9009\u62e9\u4e0a\uff0c\u53ef\u4ee5\u4f7f\u7528\u4ea4\u53c9\u68c0\u9a8c\u3002\u5c06\u6570\u636e\u5206\u7ec4\uff0c\u4e00\u7ec4\u5206\u4e3a\u8bad\u7ec3\u7ec4\uff0c\u53e6\u4e00\u7ec4\u5206\u4e3a predict \u7ec4\uff0c\u4e4b\u540e\u5c1d\u8bd5\u4e0d\u540c\u7684 alpha \u503c\uff0c\u7136\u540e\u5f97\u51fa\u4e00\u5f20 alpha -> R-squared \u7684\u5bf9\u5e94\u8868\u5355\u503c\uff0c\u6700\u540e\u51b3\u5b9a\u5e94\u8be5\u4f7f\u7528\u54ea\u4e2a alpha \u503c\u3002 from sklearn.linear_model import Ridge RidgeModel = Ridge ( alpha = 0.1 ) RidgeModel . fit ( X , y ) # R-squared RidgeModel . score ( X , y ) Yhat = RidgeModel . predict ( X )","title":"\u5cad\u56de\u5f52 Ridge Regression"},{"location":"dataAnalysis/dataAnalysis05/#grid-search","text":"\u5cad\u56de\u5f52\u4e2d\u7684 alpha \u88ab\u79f0\u4e3a hyperparameter \u8d85\u53c2\u6570\u3002Scikit-learn \u4e2d\u53ef\u4ee5\u901a\u8fc7\u7f51\u683c\u641c\u7d22\u5b9e\u73b0\u81ea\u52a8\u5316\u5c1d\u8bd5\u5404\u79cd alpha \u53c2\u6570\u7ec4\u5408\uff0c\u5e76\u4f7f\u7528\u4ea4\u53c9\u6821\u9a8c\u6765\u6838\u7b97 MSE \u4ee5\u9a8c\u8bc1\u6bcf\u79cd\u7ec4\u5408\u7684\u51c6\u786e\u6027\uff0c\u6700\u540e\u8fd4\u56de\u6700\u4f73\u7684 alpha \u7cfb\u6570\u3002 \u6570\u636e\u4f1a\u5206\u4e3a 3 \u7ec4\uff1aTraining Set, Validation Set, Test Set. \u4f7f\u7528\u4e0d\u540c\u7684 hyperparameter \u548c\u8bad\u7ec3\u6570\u636e\u6765\u8bad\u7ec3\u6a21\u578b\uff0c\u4e4b\u540e\u4f7f\u7528\u9a8c\u8bc1\u6570\u636e\u6765\u5f97\u51fa MSE \u6216 R-squared \u7684\u503c\uff0c\u9009\u62e9 MSE \u6700\u5c0f\u6216 R-squared \u6700\u5927\u60c5\u666f\u4e0b\u7684 hyperparameter \u503c\u3002\u6700\u540e\u4f7f\u7528\u5b9e\u9a8c\u7ec4\u6570\u636e\u6765\u6d4b\u8bd5\u6a21\u578b\u7684\u51c6\u786e\u6027\u3002 from sklearn.linear_model import Ridge from sklearn.model_selection import GridSearchCV parameters1 = [{ 'alpha' :[ 1 , 10 , 100 , 1000 , 10000 , 100000 ], 'normalize' :[ True , False ]}] RR = Ridge () Grid1 = GridSearchCV ( RR , parameters1 , cv = 4 ) Grid1 . fit ( x_data [[ 'horsepower' , 'curb-weight' , 'highway-mpg' ]], y_data ) Grid1 . best_estimator_ scores = Grid1 . cv_results_ scores [ 'mean_test_score' ]","title":"\u7f51\u683c\u641c\u7d22 Grid Search"}]}